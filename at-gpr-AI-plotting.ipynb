{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Figure 2 reproduction with seed=42 and verbose_optimization=False\n",
      "\n",
      "--- Starting Figure 2 Reproduction Experiment ---\n",
      "\n",
      "Processing Df_strength = 0.00 (1/30)\n",
      "\n",
      "Processing Df_strength = 1.21 (2/30)\n",
      "\n",
      "Processing Df_strength = 2.41 (3/30)\n",
      "\n",
      "Processing Df_strength = 3.62 (4/30)\n",
      "\n",
      "Processing Df_strength = 4.83 (5/30)\n",
      "\n",
      "Processing Df_strength = 6.03 (6/30)\n",
      "\n",
      "Processing Df_strength = 7.24 (7/30)\n",
      "\n",
      "Processing Df_strength = 8.45 (8/30)\n",
      "\n",
      "Processing Df_strength = 9.66 (9/30)\n",
      "\n",
      "Processing Df_strength = 10.86 (10/30)\n",
      "\n",
      "Processing Df_strength = 12.07 (11/30)\n",
      "\n",
      "Processing Df_strength = 13.28 (12/30)\n",
      "\n",
      "Processing Df_strength = 14.48 (13/30)\n",
      "\n",
      "Processing Df_strength = 15.69 (14/30)\n",
      "\n",
      "Processing Df_strength = 16.90 (15/30)\n",
      "\n",
      "Processing Df_strength = 18.10 (16/30)\n",
      "\n",
      "Processing Df_strength = 19.31 (17/30)\n",
      "\n",
      "Processing Df_strength = 20.52 (18/30)\n",
      "\n",
      "Processing Df_strength = 21.72 (19/30)\n",
      "\n",
      "Processing Df_strength = 22.93 (20/30)\n",
      "\n",
      "Processing Df_strength = 24.14 (21/30)\n",
      "\n",
      "Processing Df_strength = 25.34 (22/30)\n",
      "\n",
      "Processing Df_strength = 26.55 (23/30)\n",
      "\n",
      "Processing Df_strength = 27.76 (24/30)\n",
      "\n",
      "Processing Df_strength = 28.97 (25/30)\n",
      "\n",
      "Processing Df_strength = 30.17 (26/30)\n",
      "\n",
      "Processing Df_strength = 31.38 (27/30)\n",
      "\n",
      "Processing Df_strength = 32.59 (28/30)\n",
      "\n",
      "Processing Df_strength = 33.79 (29/30)\n",
      "\n",
      "Processing Df_strength = 35.00 (30/30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x450 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure 2 reproduction experiment finished.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Adaptive Transfer Learning Implementation\n",
    "# Authors: Bin Cao, Sinno Jialin Pan, Yu Zhang, Dit-Yan Yeung, Qiang Yang\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from scipy.optimize import minimize\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- Kernel Function ---\n",
    "class SquaredExponentialKernel:\n",
    "    def __init__(self, length_scale=1.0, sigma_f=1.0):\n",
    "        self.length_scale = length_scale\n",
    "        self.sigma_f = sigma_f\n",
    "\n",
    "    def get_params(self):\n",
    "        return np.array([self.length_scale, self.sigma_f])\n",
    "\n",
    "    def set_params(self, params):\n",
    "        self.length_scale = params[0]\n",
    "        self.sigma_f = params[1]\n",
    "\n",
    "    def __call__(self, X1, X2):\n",
    "        if X1.ndim == 1: X1 = X1[:, np.newaxis]\n",
    "        if X2.ndim == 1: X2 = X2[:, np.newaxis]\n",
    "\n",
    "        if X1.shape[1] != X2.shape[1]:\n",
    "            raise ValueError(f\"X1 and X2 must have the same number of features. Got {X1.shape[1]} and {X2.shape[1]}\")\n",
    "\n",
    "        sqdist = np.sum(X1**2, 1).reshape(-1, 1) + np.sum(X2**2, 1) - 2 * np.dot(X1, X2.T)\n",
    "        sqdist = np.clip(sqdist, 0, np.inf) # Ensure non-negative\n",
    "\n",
    "        return self.sigma_f**2 * np.exp(-0.5 / self.length_scale**2 * sqdist)\n",
    "\n",
    "# Helper to compute covariance matrix\n",
    "def calculate_covariance_matrix(X1, X2, kernel_func):\n",
    "    return kernel_func(X1, X2)\n",
    "\n",
    "# --- Metrics ---\n",
    "def nmse(y_true, y_pred):\n",
    "    y_true_v = np.asarray(y_true).flatten()\n",
    "    y_pred_v = np.asarray(y_pred).flatten()\n",
    "    if len(y_true_v) == 0 or len(y_pred_v) == 0: return np.nan\n",
    "    mse = np.mean((y_true_v - y_pred_v)**2)\n",
    "    var_true = np.var(y_true_v)\n",
    "    if var_true < 1e-9: # Avoid division by zero if true values are constant\n",
    "        return mse if mse > 1e-9 else 0.0\n",
    "    return mse / var_true\n",
    "\n",
    "def error_distance(y_true, y_pred): # This is RMSE for 1D output, or mean Euclidean for multi-output\n",
    "    y_true_v = np.asarray(y_true)\n",
    "    y_pred_v = np.asarray(y_pred)\n",
    "    if y_true_v.ndim == 1: y_true_v = y_true_v.reshape(-1,1)\n",
    "    if y_pred_v.ndim == 1: y_pred_v = y_pred_v.reshape(-1,1)\n",
    "\n",
    "    if y_true_v.shape[0] == 0 or y_pred_v.shape[0] == 0: return np.nan\n",
    "    # For 1D output, this is equivalent to RMSE\n",
    "    return np.mean(np.sqrt(np.sum((y_true_v - y_pred_v)**2, axis=1)))\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true_v = np.asarray(y_true).flatten()\n",
    "    y_pred_v = np.asarray(y_pred).flatten()\n",
    "    if len(y_true_v) == 0 or len(y_pred_v) == 0: return np.nan\n",
    "    return np.mean(np.abs(y_true_v - y_pred_v))\n",
    "\n",
    "# --- AT-GP Model (from paper) ---\n",
    "class ATGP:\n",
    "    def __init__(self, X_S, y_S, X_T, y_T,\n",
    "                 initial_length_scale=1.0, initial_sigma_f=1.0,\n",
    "                 initial_b=1.0, initial_mu=1.0,\n",
    "                 initial_noise_S_std=0.1, initial_noise_T_std=0.1):\n",
    "        self.X_S = X_S\n",
    "        self.y_S = y_S.reshape(-1, 1)\n",
    "        self.X_T = X_T\n",
    "        self.y_T = y_T.reshape(-1, 1)\n",
    "\n",
    "        self._length_scale = initial_length_scale\n",
    "        self._sigma_f = initial_sigma_f\n",
    "        self._b = initial_b\n",
    "        self._mu = initial_mu\n",
    "        self._noise_S_std = initial_noise_S_std\n",
    "        self._noise_T_std = initial_noise_T_std\n",
    "\n",
    "        self.base_kernel = SquaredExponentialKernel(self._length_scale, self._sigma_f)\n",
    "        self.fitted = False\n",
    "        self.optimized_params_ = {}\n",
    "\n",
    "    def _get_params_array(self):\n",
    "        return np.array([self._length_scale, self._sigma_f, self._b, self._mu,\n",
    "                         self._noise_S_std, self._noise_T_std])\n",
    "\n",
    "    def _set_params_from_array(self, params_array):\n",
    "        self._length_scale = params_array[0]\n",
    "        self._sigma_f = params_array[1]\n",
    "        self.base_kernel.set_params(params_array[:2])\n",
    "        self._b = params_array[2]\n",
    "        self._mu = params_array[3]\n",
    "        self._noise_S_std = params_array[4]\n",
    "        self._noise_T_std = params_array[5]\n",
    "\n",
    "    def _get_lambda(self, b_param=None, mu_param=None):\n",
    "        b_to_use = b_param if b_param is not None else self._b\n",
    "        mu_to_use = mu_param if mu_param is not None else self._mu\n",
    "        \n",
    "        # Ensure parameters are positive where needed\n",
    "        b_to_use = max(1e-5, b_to_use) # b > 0\n",
    "        # mu > -1 for (1+mu) to be positive.\n",
    "        # Optimizer bound for mu is (1e-5, 1e2), so 1+mu will be > 1.\n",
    "        # If mu comes from an unconstrained optimization, it might need clipping:\n",
    "        # mu_to_use = max(-1 + 1e-5, mu_to_use) \n",
    "\n",
    "        term_base = 1.0 / (1.0 + mu_to_use) # If mu bound is (1e-5, 1e2), then 1+mu is (1.00001, 101)\n",
    "                                          # So term_base is (1/101, 1/1.00001) approx (0.0099, 0.99999)\n",
    "        lambda_val = -1.0\n",
    "        if term_base < 0 : # Should not happen with current mu bounds\n",
    "             lambda_val = -1.0 \n",
    "        # Original paper's lambda definition implies term_base can be > 1 if -1 < mu < 0.\n",
    "        # With current bounds, term_base is always (0,1).\n",
    "        # elif abs(term_base) > 1e6 and b_to_use > 1 and term_base > 0: # Avoid overflow for huge base\n",
    "        #     lambda_val = 1.0\n",
    "        else:\n",
    "            try:\n",
    "                pow_term = np.power(term_base, b_to_use)\n",
    "                lambda_val = 2 * pow_term - 1\n",
    "            except (OverflowError, ValueError): # Catch issues with np.power\n",
    "                # If term_base is (0,1), pow_term is (0,1). lambda is (-1,1)\n",
    "                # If term_base > 1 (i.e. -1 < mu < 0), pow_term can be large.\n",
    "                # lambda_val = 1.0 if term_base > 1 else -1.0 # Fallback\n",
    "                # Given current mu bounds, this fallback logic is less critical.\n",
    "                # If mu -> -1 from above, term_base -> +inf. If b > 0, pow_term -> +inf. lambda -> +inf.\n",
    "                # If mu is large positive, term_base -> 0. pow_term -> 0. lambda -> -1.\n",
    "                 lambda_val = np.sign(2 * (0.5 if term_base > 1 else 0) -1) * 1.0 # A safe fallback\n",
    "\n",
    "        return np.clip(lambda_val, -1.0, 1.0)\n",
    "\n",
    "\n",
    "    def log_marginal_likelihood_conditional(self, params_array_opt):\n",
    "        # Ensure params are within reasonable bounds (especially positive for std devs, ls, sf)\n",
    "        params_array_opt = np.maximum(params_array_opt, 1e-5) # Element-wise max with 1e-5\n",
    "\n",
    "        current_length_scale = params_array_opt[0]\n",
    "        current_sigma_f = params_array_opt[1]\n",
    "        temp_kernel = SquaredExponentialKernel(current_length_scale, current_sigma_f)\n",
    "\n",
    "        current_b = params_array_opt[2]\n",
    "        current_mu = params_array_opt[3] # mu itself will be > 1e-5\n",
    "        temp_lambda = self._get_lambda(b_param=current_b, mu_param=current_mu)\n",
    "\n",
    "        current_noise_S_var = params_array_opt[4]**2\n",
    "        current_noise_T_var = params_array_opt[5]**2\n",
    "\n",
    "        jitter = 1e-7 # Small jitter for numerical stability\n",
    "\n",
    "        K11 = calculate_covariance_matrix(self.X_S, self.X_S, temp_kernel)\n",
    "        K22 = calculate_covariance_matrix(self.X_T, self.X_T, temp_kernel)\n",
    "        K_TS_base = calculate_covariance_matrix(self.X_T, self.X_S, temp_kernel) # K_2S\n",
    "\n",
    "        K21 = temp_lambda * K_TS_base # K_2S * lambda\n",
    "        K12 = K21.T # (K_2S * lambda)^T = K_S2 * lambda\n",
    "\n",
    "        try:\n",
    "            # Equation (7) from paper: p(y_T | y_S, X_S, X_T, theta_c)\n",
    "            # mu_t_cond = K21 @ inv(K11 + sigma_nS^2*I) @ y_S\n",
    "            # C_t_cond = K22 - K21 @ inv(K11 + sigma_nS^2*I) @ K12 + sigma_nT^2*I\n",
    "            \n",
    "            K11_noisy = K11 + current_noise_S_var * np.eye(K11.shape[0]) + jitter * np.eye(K11.shape[0])\n",
    "            L_K11_noisy = np.linalg.cholesky(K11_noisy)\n",
    "\n",
    "            # K11_noisy_inv_yS = inv(K11_noisy) @ y_S\n",
    "            K11_noisy_inv_yS = scipy.linalg.solve_triangular(L_K11_noisy.T, \n",
    "                                   scipy.linalg.solve_triangular(L_K11_noisy, self.y_S, lower=True, check_finite=False), \n",
    "                                   lower=False, check_finite=False)\n",
    "            mu_t = K21 @ K11_noisy_inv_yS\n",
    "\n",
    "            # K11_noisy_inv_K12 = inv(K11_noisy) @ K12\n",
    "            K11_noisy_inv_K12 = scipy.linalg.solve_triangular(L_K11_noisy.T, \n",
    "                                    scipy.linalg.solve_triangular(L_K11_noisy, K12, lower=True, check_finite=False), \n",
    "                                    lower=False, check_finite=False)\n",
    "\n",
    "            C_t_main_term = K22 - K21 @ K11_noisy_inv_K12\n",
    "            C_t = C_t_main_term + current_noise_T_var * np.eye(K22.shape[0]) + jitter * np.eye(K22.shape[0])\n",
    "\n",
    "            L_Ct = np.linalg.cholesky(C_t)\n",
    "            log_det_Ct = 2 * np.sum(np.log(np.diag(L_Ct)))\n",
    "\n",
    "            y_T_minus_mu_t = self.y_T - mu_t\n",
    "            # Ct_inv_y_minus_mu = inv(C_t) @ y_T_minus_mu_t\n",
    "            Ct_inv_y_minus_mu = scipy.linalg.solve_triangular(L_Ct.T, \n",
    "                                    scipy.linalg.solve_triangular(L_Ct, y_T_minus_mu_t, lower=True, check_finite=False),\n",
    "                                    lower=False, check_finite=False)\n",
    "            \n",
    "            term2_quadratic = y_T_minus_mu_t.T @ Ct_inv_y_minus_mu\n",
    "        except np.linalg.LinAlgError:\n",
    "            # print(\"LinAlgError in ATGP LML calc\")\n",
    "            return -np.inf # Penalize unstable parameters heavily\n",
    "        \n",
    "        log_likelihood = -0.5 * log_det_Ct - 0.5 * term2_quadratic - len(self.y_T)/2.0 * np.log(2 * np.pi)\n",
    "\n",
    "        if np.isnan(log_likelihood) or not np.isfinite(log_likelihood):\n",
    "            return -np.inf\n",
    "        return log_likelihood.item()\n",
    "\n",
    "    def fit(self, method='L-BFGS-B', disp=False, maxiter=200):\n",
    "        initial_params = self._get_params_array()\n",
    "        if disp:\n",
    "            print(\"  Starting AT-GP optimization...\")\n",
    "            print(f\"    Initial AT-GP params (ls, sf, b, mu, noise_S, noise_T): {np.round(initial_params,3)}\")\n",
    "            print(f\"    Initial AT-GP lambda: {self._get_lambda():.3f}\")\n",
    "\n",
    "\n",
    "        # Bounds for parameters: [length_scale, sigma_f, b, mu, noise_S_std, noise_T_std]\n",
    "        bounds = [\n",
    "            (1e-5, 1e3),  # length_scale\n",
    "            (1e-5, 1e3),  # sigma_f\n",
    "            (1e-5, 1e2),  # b (b>0)\n",
    "            (1e-5, 1e2),  # mu (mu>0 ensures 1+mu>1, so 1/(1+mu) is (0,1))\n",
    "                          # Paper implies mu > -1. If mu can be (-1, 0), then 1/(1+mu) > 1.\n",
    "                          # For simplicity and stability matching some GP implementations, mu > 0 is safer.\n",
    "            (1e-5, 1e2),  # noise_S_std\n",
    "            (1e-5, 1e2)   # noise_T_std\n",
    "        ]\n",
    "\n",
    "        objective = lambda params_opt: -self.log_marginal_likelihood_conditional(params_opt)\n",
    "\n",
    "        result = minimize(objective, initial_params, method=method, bounds=bounds, \n",
    "                          options={'disp': disp, 'maxiter': maxiter, 'ftol': 1e-7, 'gtol': 1e-5})\n",
    "\n",
    "        if disp:\n",
    "            print(\"  AT-GP optimization finished.\")\n",
    "            print(f\"    Success: {result.success}, Message: {result.message}\")\n",
    "            print(f\"    Optimized AT-GP params (ls, sf, b, mu, noise_S, noise_T): {np.round(result.x,3)}\")\n",
    "\n",
    "\n",
    "        # Set params even if not fully converged, as result.x is the best found.\n",
    "        self._set_params_from_array(result.x)\n",
    "        self.fitted = True\n",
    "        self.optimized_params_ = dict(zip(['ls', 'sf', 'b', 'mu', 'noise_S_std', 'noise_T_std', 'lambda_val'],\n",
    "                                       list(np.round(result.x,4)) + [np.round(self._get_lambda(),4)]))\n",
    "        if disp:\n",
    "             print(f\"    Optimized AT-GP lambda: {self._get_lambda():.3f}\")\n",
    "        \n",
    "        if not result.success and \"CONVERGENCE\" not in result.message.upper():\n",
    "             if disp:\n",
    "                print(f\"    Warning: AT-GP Optimization may not have fully converged: {result.message}\")\n",
    "           \n",
    "        return result\n",
    "\n",
    "    def predict(self, X_star_T): # Predicts for target tasks based on X_star_T\n",
    "        if not self.fitted :\n",
    "             print(\"Warning: ATGP model is not fitted. Predictions based on initial parameters.\")\n",
    "\n",
    "        lambda_val = self._get_lambda()\n",
    "        noise_S_var_val = self._noise_S_std**2\n",
    "        noise_T_var_val = self._noise_T_std**2 # This is sigma_nT^2 from paper notation\n",
    "        jitter = 1e-7\n",
    "\n",
    "        N_S = self.X_S.shape[0]\n",
    "        N_T = self.X_T.shape[0]\n",
    "        N_all = N_S + N_T\n",
    "\n",
    "        y_all = np.vstack((self.y_S, self.y_T)) # [y_S; y_T]\n",
    "\n",
    "        # Construct K_tilde based on Equation (8)\n",
    "        K_SS = calculate_covariance_matrix(self.X_S, self.X_S, self.base_kernel)\n",
    "        K_TT = calculate_covariance_matrix(self.X_T, self.X_T, self.base_kernel)\n",
    "        K_ST_base = calculate_covariance_matrix(self.X_S, self.X_T, self.base_kernel) # K_ST in math, (N_S, N_T)\n",
    "\n",
    "        K_tilde = np.zeros((N_all, N_all))\n",
    "        K_tilde[:N_S, :N_S] = K_SS\n",
    "        K_tilde[N_S:, N_S:] = K_TT\n",
    "        K_tilde[:N_S, N_S:] = lambda_val * K_ST_base\n",
    "        K_tilde[N_S:, :N_S] = lambda_val * K_ST_base.T\n",
    "\n",
    "        # Construct Big_Lambda_tilde based on Equation (8)\n",
    "        Big_Lambda_diag = np.concatenate([np.full(N_S, noise_S_var_val),\n",
    "                                          np.full(N_T, noise_T_var_val)])\n",
    "        Big_Lambda = np.diag(Big_Lambda_diag)\n",
    "\n",
    "        C_tilde = K_tilde + Big_Lambda + jitter * np.eye(N_all) # This is K_c in paper Eq (10)\n",
    "        L_Ctilde = None\n",
    "        try:\n",
    "            L_Ctilde = np.linalg.cholesky(C_tilde)\n",
    "            alpha = scipy.linalg.solve_triangular(L_Ctilde.T, \n",
    "                        scipy.linalg.solve_triangular(L_Ctilde, y_all, lower=True, check_finite=False), \n",
    "                        lower=False, check_finite=False)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Fallback to pseudo-inverse if Cholesky fails\n",
    "            # print(\"Warning: Cholesky failed in ATGP predict. Using PINV.\")\n",
    "            C_tilde_inv = np.linalg.pinv(C_tilde)\n",
    "            alpha = C_tilde_inv @ y_all\n",
    "\n",
    "        # Prediction for new target points X_star_T (denoted x* in paper)\n",
    "        # k_x_star from paper Eq (10) is [lambda * k(x*, X_S), k(x*, X_T)]^T\n",
    "        # So, k_x_star_rows should be [lambda * k(X_star_T, X_S), k(X_star_T, X_T)]\n",
    "        k_star_S_base = calculate_covariance_matrix(X_star_T, self.X_S, self.base_kernel) # (N_star, N_S)\n",
    "        k_star_T_base = calculate_covariance_matrix(X_star_T, self.X_T, self.base_kernel) # (N_star, N_T)\n",
    "        \n",
    "        k_x_star_rows = np.hstack((lambda_val * k_star_S_base, k_star_T_base)) # (N_star, N_all)\n",
    "\n",
    "        mean_star = k_x_star_rows @ alpha # Eq (10) mean part\n",
    "\n",
    "        # Variance part of Eq (10): k(x*,x*) + sigma_nT^2 - k_x*^T @ inv(K_c) @ k_x*\n",
    "        # k(x*,x*) is K_TT(X_star_T, X_star_T)\n",
    "        k_star_star_diag = np.diag(self.base_kernel(X_star_T, X_star_T))\n",
    "        # The noise term for target predictions is sigma_nT^2\n",
    "        c_diag = k_star_star_diag + noise_T_var_val \n",
    "\n",
    "        if L_Ctilde is not None:\n",
    "            # v = inv(L_Ctilde) @ k_x_star (as columns)\n",
    "            v = scipy.linalg.solve_triangular(L_Ctilde, k_x_star_rows.T, lower=True, check_finite=False)\n",
    "            # var_reduction_diag = diag(k_x_star^T @ inv(C_tilde) @ k_x_star) = sum(v.^2, axis=0)\n",
    "            var_reduction_diag = np.sum(v**2, axis=0) \n",
    "        else: \n",
    "            # Fallback if Cholesky failed earlier\n",
    "            var_reduction_diag = np.diag(k_x_star_rows @ C_tilde_inv @ k_x_star_rows.T)\n",
    "\n",
    "\n",
    "        variance_star_diag = c_diag - var_reduction_diag\n",
    "        variance_star_diag = np.clip(variance_star_diag, jitter, np.inf) # Ensure positive variance\n",
    "\n",
    "        return mean_star, variance_star_diag.reshape(-1,1)\n",
    "\n",
    "\n",
    "# --- Simple GPR for Baselines ---\n",
    "class SimpleGPR:\n",
    "    def __init__(self, initial_length_scale=1.0, initial_sigma_f=1.0, initial_noise_std=0.1):\n",
    "        self._length_scale = initial_length_scale\n",
    "        self._sigma_f = initial_sigma_f\n",
    "        self._noise_std = initial_noise_std\n",
    "        self.kernel = SquaredExponentialKernel(self._length_scale, self._sigma_f)\n",
    "        self.X_train, self.y_train, self.alpha_, self.L_ = None, None, None, None\n",
    "        self.fitted = False\n",
    "        self.optimized_params_ = {}\n",
    "\n",
    "\n",
    "    def _get_params_array(self):\n",
    "        return np.array([self._length_scale, self._sigma_f, self._noise_std])\n",
    "\n",
    "    def _set_params_from_array(self, params_array):\n",
    "        self._length_scale = params_array[0]\n",
    "        self._sigma_f = params_array[1]\n",
    "        self.kernel.set_params(params_array[:2])\n",
    "        self._noise_std = params_array[2]\n",
    "\n",
    "    def log_marginal_likelihood(self, params_array_opt, X, y):\n",
    "        params_array_opt = np.maximum(params_array_opt, 1e-5) # Ensure positive\n",
    "        current_length_scale, current_sigma_f = params_array_opt[0], params_array_opt[1]\n",
    "        temp_kernel = SquaredExponentialKernel(current_length_scale, current_sigma_f)\n",
    "        current_noise_var = params_array_opt[2]**2\n",
    "        jitter = 1e-7\n",
    "\n",
    "        N = X.shape[0]\n",
    "        if N == 0: return -np.inf # No data\n",
    "        K = calculate_covariance_matrix(X, X, temp_kernel)\n",
    "        K_noisy = K + current_noise_var * np.eye(N) + jitter * np.eye(N)\n",
    "\n",
    "        try:\n",
    "            L = np.linalg.cholesky(K_noisy)\n",
    "            alpha_solve = scipy.linalg.solve_triangular(L.T, \n",
    "                                scipy.linalg.solve_triangular(L, y, lower=True, check_finite=False), \n",
    "                                lower=False, check_finite=False)\n",
    "            log_det_K_noisy = 2 * np.sum(np.log(np.diag(L)))\n",
    "        except np.linalg.LinAlgError: \n",
    "            # print(\"LinAlgError in SimpleGPR LML\")\n",
    "            return -np.inf\n",
    "\n",
    "        lml = -0.5 * y.T @ alpha_solve - 0.5 * log_det_K_noisy - N/2.0 * np.log(2 * np.pi)\n",
    "        if np.isnan(lml) or not np.isfinite(lml): return -np.inf\n",
    "        return lml.item()\n",
    "\n",
    "    def fit(self, X_train, y_train, method='L-BFGS-B', disp=False, maxiter=100, model_name_for_print=\"SimpleGPR\"):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train.reshape(-1,1)\n",
    "\n",
    "        initial_params = self._get_params_array()\n",
    "        if disp:\n",
    "            print(f\"  Starting {model_name_for_print} optimization...\")\n",
    "            print(f\"    Initial params (ls, sf, noise_std): {np.round(initial_params,3)}\")\n",
    "\n",
    "        bounds = [(1e-5, 1e3), (1e-5, 1e3), (1e-5, 1e2)] # ls, sf, noise_std\n",
    "\n",
    "        objective = lambda params_opt: -self.log_marginal_likelihood(params_opt, self.X_train, self.y_train)\n",
    "        result = minimize(objective, initial_params, method=method, bounds=bounds, \n",
    "                          options={'disp': disp, 'maxiter': maxiter, 'ftol': 1e-7, 'gtol': 1e-5})\n",
    "\n",
    "        if disp:\n",
    "            print(f\"  {model_name_for_print} optimization finished.\")\n",
    "            print(f\"    Success: {result.success}, Message: {result.message}\")\n",
    "            print(f\"    Optimized params (ls, sf, noise_std): {np.round(result.x,3)}\")\n",
    "\n",
    "        self._set_params_from_array(result.x)\n",
    "        self.optimized_params_ = dict(zip(['ls', 'sf', 'noise_std'], np.round(result.x,4)))\n",
    "\n",
    "        K_final = self.kernel(self.X_train, self.X_train)\n",
    "        K_noisy_final = K_final + (self._noise_std**2) * np.eye(self.X_train.shape[0]) + 1e-7 * np.eye(self.X_train.shape[0])\n",
    "        try:\n",
    "            self.L_ = np.linalg.cholesky(K_noisy_final)\n",
    "            self.alpha_ = scipy.linalg.solve_triangular(self.L_.T, \n",
    "                            scipy.linalg.solve_triangular(self.L_, self.y_train, lower=True, check_finite=False), \n",
    "                            lower=False, check_finite=False)\n",
    "            self.fitted = True\n",
    "        except np.linalg.LinAlgError:\n",
    "            if disp:\n",
    "                print(f\"    Warning: Cholesky failed in {model_name_for_print} fit post-optimization. Using PINV for prediction.\")\n",
    "            # Fallback to pseudo-inverse\n",
    "            K_noisy_inv = np.linalg.pinv(K_noisy_final)\n",
    "            self.alpha_ = K_noisy_inv @ self.y_train\n",
    "            self.L_ = None # Indicate Cholesky failed\n",
    "            self.fitted = True # Still allow prediction\n",
    "        return result\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        if not self.fitted: raise RuntimeError(\"SimpleGPR must be fitted before prediction.\")\n",
    "        if X_star.shape[0] == 0: return np.array([]), np.array([])\n",
    "        jitter = 1e-9\n",
    "\n",
    "        K_star = self.kernel(X_star, self.X_train) # K(X_star, X_train)\n",
    "        mean_star = K_star @ self.alpha_\n",
    "        \n",
    "        K_star_star_diag = np.diag(self.kernel(X_star, X_star)) # Diagonal of K(X_star, X_star)\n",
    "        \n",
    "        if self.L_ is not None: # Cholesky factor available\n",
    "            # v = inv(L) @ K_star.T\n",
    "            v = scipy.linalg.solve_triangular(self.L_, K_star.T, lower=True, check_finite=False)\n",
    "            # var_reduction_diag = diag(K_star @ inv(K_noisy) @ K_star.T) = sum(v.^2, axis=0)\n",
    "            var_reduction_diag = np.sum(v**2, axis=0)\n",
    "        else: # Cholesky failed, use pseudo-inverse (slower)\n",
    "            K_noisy = self.kernel(self.X_train, self.X_train) + \\\n",
    "                      (self._noise_std**2) * np.eye(self.X_train.shape[0]) + \\\n",
    "                      1e-7 * np.eye(self.X_train.shape[0])\n",
    "            K_noisy_inv = np.linalg.pinv(K_noisy)\n",
    "            var_reduction_diag = np.diag(K_star @ K_noisy_inv @ K_star.T)\n",
    "\n",
    "        variance_star_diag = K_star_star_diag + (self._noise_std**2) - var_reduction_diag\n",
    "        variance_star_diag = np.clip(variance_star_diag, jitter, np.inf) # Ensure positive\n",
    "\n",
    "        return mean_star, variance_star_diag.reshape(-1,1)\n",
    "\n",
    "\n",
    "# --- Experiment Functions (Wine, Sarcos, SimWiFi - kept for completeness) ---\n",
    "def run_wine_experiment(verbose_optimization, seed):\n",
    "    print(\"\\n--- Starting WINE Dataset Experiment ---\")\n",
    "    try:\n",
    "        wine_white_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
    "        wine_red_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load wine datasets: {e}. Skipping WINE experiment.\")\n",
    "        return None\n",
    "\n",
    "    X_S_raw = wine_white_df.drop('quality', axis=1).values\n",
    "    y_S_raw = wine_white_df['quality'].values\n",
    "    X_T_raw = wine_red_df.drop('quality', axis=1).values\n",
    "    y_T_raw = wine_red_df['quality'].values\n",
    "\n",
    "    scaler_S = StandardScaler()\n",
    "    X_S = scaler_S.fit_transform(X_S_raw)\n",
    "\n",
    "    scaler_T_all_wine = StandardScaler()\n",
    "    X_T_scaled_all = scaler_T_all_wine.fit_transform(X_T_raw)\n",
    "\n",
    "    # Use a small portion of target data for training, e.g., 5% as in paper.\n",
    "    # Ensure there are enough samples for a meaningful split.\n",
    "    train_size_target = 0.05\n",
    "    if int(X_T_scaled_all.shape[0] * train_size_target) < 2 : # Need at least 2 samples for GPR\n",
    "        train_size_target = min(1.0, 2.0 / X_T_scaled_all.shape[0] if X_T_scaled_all.shape[0]>0 else 1.0)\n",
    "        if int(X_T_scaled_all.shape[0] * train_size_target) < 2 and X_T_scaled_all.shape[0] >= 2:\n",
    "             # if still less than 2, but have at least 2, use 2.\n",
    "             train_size_target = 2\n",
    "        elif X_T_scaled_all.shape[0] < 2:\n",
    "            print(\"Not enough target samples in Wine to split. Skipping.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    X_T_train, X_T_test, y_T_train, y_T_test = train_test_split(\n",
    "        X_T_scaled_all, y_T_raw, train_size=train_size_target, random_state=seed, stratify=(y_T_raw if len(np.unique(y_T_raw)) > 1 else None)\n",
    "    )\n",
    "    if X_T_train.shape[0] == 0 or X_T_test.shape[0] == 0:\n",
    "        print(\"Wine dataset split resulted in empty train or test set. Skipping.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    print(f\"Source (White Wine): X_S {X_S.shape}, y_S {y_S_raw.shape}\")\n",
    "    print(f\"Target (Red Wine) All: X_T_scaled_all {X_T_scaled_all.shape}, y_T {y_T_raw.shape}\")\n",
    "    print(f\"Target Train: X_T_train {X_T_train.shape}, y_T_train {y_T_train.shape} (train_size={train_size_target if isinstance(train_size_target, float) else train_size_target/X_T_scaled_all.shape[0] :.2%})\")\n",
    "    print(f\"Target Test: X_T_test {X_T_test.shape}, y_T_test {y_T_test.shape}\")\n",
    "\n",
    "    results = {}\n",
    "    default_ls, default_sf, default_noise = 1.0, 1.0, 0.5\n",
    "    default_b, default_mu = 1.0, 1.0 \n",
    "\n",
    "    print(\"\\n--- Training AT-GP Model (Wine) ---\")\n",
    "    atgp_model = ATGP(X_S, y_S_raw, X_T_train, y_T_train,\n",
    "                      initial_length_scale=default_ls, initial_sigma_f=default_sf,\n",
    "                      initial_b=default_b, initial_mu=default_mu,\n",
    "                      initial_noise_S_std=default_noise, initial_noise_T_std=default_noise)\n",
    "    atgp_model.fit(disp=verbose_optimization, maxiter=100)\n",
    "    mean_atgp, _ = atgp_model.predict(X_T_test)\n",
    "    results['AT-GP'] = nmse(y_T_test, mean_atgp)\n",
    "    print(f\"AT-GP NMSE (Wine): {results['AT-GP']:.4f}, Params: {atgp_model.optimized_params_}\")\n",
    "\n",
    "    print(\"\\n--- Training No Transfer GP Model (Wine) ---\")\n",
    "    gp_no_transfer = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_no_transfer.fit(X_T_train, y_T_train, disp=verbose_optimization, maxiter=100, model_name_for_print=\"No Transfer GP (Wine)\")\n",
    "    mean_no_transfer, _ = gp_no_transfer.predict(X_T_test)\n",
    "    results['No Transfer GP'] = nmse(y_T_test, mean_no_transfer)\n",
    "    print(f\"No Transfer GP NMSE (Wine): {results['No Transfer GP']:.4f}, Params: {gp_no_transfer.optimized_params_}\")\n",
    "\n",
    "    print(\"\\n--- Training Transfer All GP Model (Wine) ---\")\n",
    "    X_S_rescaled_for_All = scaler_T_all_wine.transform(scaler_S.inverse_transform(X_S)) # Use the overall target scaler\n",
    "    X_all_train = np.vstack((X_S_rescaled_for_All, X_T_train))\n",
    "    y_all_train = np.concatenate((y_S_raw, y_T_train))\n",
    "\n",
    "    gp_transfer_all = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_transfer_all.fit(X_all_train, y_all_train, disp=verbose_optimization, maxiter=100, model_name_for_print=\"Transfer All GP (Wine)\")\n",
    "    mean_transfer_all, _ = gp_transfer_all.predict(X_T_test)\n",
    "    results['Transfer All GP'] = nmse(y_T_test, mean_transfer_all)\n",
    "    print(f\"Transfer All GP NMSE (Wine): {results['Transfer All GP']:.4f}, Params: {gp_transfer_all.optimized_params_}\")\n",
    "\n",
    "    print(\"\\n--- Summary of NMSE Results on WINE Dataset ---\")\n",
    "    for model_name, score in results.items():\n",
    "        print(f\"{model_name}: {score:.4f}\")\n",
    "    return results\n",
    "\n",
    "# --- FIGURE 2 REPRODUCTION EXPERIMENT ---\n",
    "def run_figure2_experiment(seed=42, verbose_optimization=False):\n",
    "    print(\"\\n--- Starting Figure 2 Reproduction Experiment ---\")\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    # --- Experiment Parameters (based on paper's synthetic sinc experiment) ---\n",
    "    n_features = 1 \n",
    "    n_source_samples = 100  # Paper: \"100 source data points\"\n",
    "    n_target_pool = 50      # Paper: \"20 for training and 30 for testing\"\n",
    "    target_train_fraction = 20.0 / n_target_pool #  20 training target points\n",
    "    \n",
    "    constant_offset_target = 0.5 # Paper: \"offset is a constant value set to 0.5\"\n",
    "    noise_std_data = 0.1         # Paper: \"Gaussian noise N(0,0.1^2)\"\n",
    "\n",
    "    # D_f values (distance parameter from paper)\n",
    "    Df_values = np.linspace(0, 35, 30) # Iterate D_f from 0 to 35\n",
    "\n",
    "    # Store results\n",
    "    mae_atgp_list = []\n",
    "    mae_no_transfer_list = []\n",
    "    mae_transfer_all_list = []\n",
    "    lambda_atgp_list = []\n",
    "\n",
    "    # --- Scaling y values to [0, 100] ---\n",
    "    # Theoretical range of sinc(x) is approx [-0.217, 1.0]\n",
    "    # f_S(x) = sinc(x) -> range approx [-0.217, 1.0]\n",
    "    # f_T(x) = sinc(x-D_f) + offset -> range approx [-0.217 + 0.5, 1.0 + 0.5] = [0.283, 1.5]\n",
    "    # Global range for scaling: min_y = -0.217, max_y = 1.5\n",
    "    global_min_y_for_scaling = -0.21723362821122155 \n",
    "    global_max_y_for_scaling = 1.0 + constant_offset_target \n",
    "    \n",
    "    def scale_y_to_100(y_vals):\n",
    "        return (y_vals - global_min_y_for_scaling) / \\\n",
    "               (global_max_y_for_scaling - global_min_y_for_scaling) * 100\n",
    "\n",
    "    # Estimate noise on scaled y for GP initialization\n",
    "    # Scale factor is 100 / (1.5 - (-0.217)) approx 100 / 1.717 = 58.23\n",
    "    # So, noise_std_data * 58.23 = 0.1 * 58.23 = 5.823\n",
    "    scaled_noise_estimate = noise_std_data * 100 / (global_max_y_for_scaling - global_min_y_for_scaling)\n",
    "\n",
    "    # Default GP hyperparameters (initial guesses)\n",
    "    default_ls, default_sf = 1.0, 10.0 # sf might need to be larger for y in [0,100]\n",
    "    default_noise_gp = max(1.0, scaled_noise_estimate) # Initial noise for GPs (optimized)\n",
    "    default_b, default_mu = 1.0, 1.0 # Initial b, mu for AT-GP\n",
    "\n",
    "    max_iter_gp = 50 # Optimization iterations (can be increased for better convergence)\n",
    "\n",
    "    for i, Df_strength in enumerate(Df_values):\n",
    "        print(f\"\\nProcessing Df_strength = {Df_strength:.2f} ({i+1}/{len(Df_values)})\")\n",
    "\n",
    "        # --- Generate Data ---\n",
    "        # Source Data: x_S from U[-15, -5], y_S = sinc(x_S) + noise\n",
    "        X_S_raw = rng.uniform(-15, -5, size=(n_source_samples, n_features))\n",
    "        y_S_unscaled = np.sinc(X_S_raw) + rng.randn(n_source_samples, n_features) * noise_std_data\n",
    "        y_S_scaled_flat = scale_y_to_100(y_S_unscaled.ravel())\n",
    "\n",
    "        # Target Data: x_T from U[5, 15], y_T = sinc(x_T - Df) + offset + noise\n",
    "        X_T_pool_raw = rng.uniform(5, 15, size=(n_target_pool, n_features))\n",
    "        y_T_pool_unscaled = np.sinc(X_T_pool_raw - Df_strength) + constant_offset_target + \\\n",
    "                            rng.randn(n_target_pool, n_features) * noise_std_data\n",
    "        y_T_pool_scaled_flat = scale_y_to_100(y_T_pool_unscaled.ravel())\n",
    "        \n",
    "        # Split target data (scaled y)\n",
    "        X_T_train_raw, X_T_test_raw, y_T_train_scaled_flat, y_T_test_scaled_flat = train_test_split(\n",
    "            X_T_pool_raw, y_T_pool_scaled_flat, train_size=target_train_fraction, random_state=seed + i \n",
    "        )\n",
    "        \n",
    "        # --- Preprocessing X ---\n",
    "        scaler_S = StandardScaler()\n",
    "        X_S = scaler_S.fit_transform(X_S_raw)\n",
    "\n",
    "        scaler_T_train = StandardScaler()\n",
    "        X_T_train = scaler_T_train.fit_transform(X_T_train_raw)\n",
    "        X_T_test = scaler_T_train.transform(X_T_test_raw)\n",
    "\n",
    "        # --- AT-GP ---\n",
    "        # print(\"  Training AT-GP...\")\n",
    "        atgp_model = ATGP(X_S, y_S_scaled_flat, X_T_train, y_T_train_scaled_flat,\n",
    "                          initial_length_scale=default_ls, initial_sigma_f=default_sf,\n",
    "                          initial_b=default_b, initial_mu=default_mu,\n",
    "                          initial_noise_S_std=default_noise_gp, \n",
    "                          initial_noise_T_std=default_noise_gp)\n",
    "        atgp_model.fit(disp=verbose_optimization, maxiter=max_iter_gp)\n",
    "        mean_atgp, _ = atgp_model.predict(X_T_test)\n",
    "        mae_atgp_list.append(mae(y_T_test_scaled_flat, mean_atgp))\n",
    "        lambda_atgp_list.append(atgp_model._get_lambda())\n",
    "        if verbose_optimization:\n",
    "            print(f\"    AT-GP MAE: {mae_atgp_list[-1]:.3f}, Lambda: {lambda_atgp_list[-1]:.3f}\")\n",
    "            print(f\"    AT-GP Optimized Params: {atgp_model.optimized_params_}\")\n",
    "\n",
    "\n",
    "        # --- No Transfer GP ---\n",
    "        # print(\"  Training No Transfer GP...\")\n",
    "        gp_no_transfer = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, \n",
    "                                   initial_noise_std=default_noise_gp)\n",
    "        gp_no_transfer.fit(X_T_train, y_T_train_scaled_flat, disp=verbose_optimization, maxiter=max_iter_gp, \n",
    "                           model_name_for_print=f\"NoTrans Df={Df_strength:.1f}\")\n",
    "        mean_no_transfer, _ = gp_no_transfer.predict(X_T_test)\n",
    "        mae_no_transfer_list.append(mae(y_T_test_scaled_flat, mean_no_transfer))\n",
    "        if verbose_optimization:\n",
    "            print(f\"    No Transfer GP MAE: {mae_no_transfer_list[-1]:.3f}\")\n",
    "            print(f\"    NoTrans Optimized Params: {gp_no_transfer.optimized_params_}\")\n",
    "\n",
    "        # --- Transfer All GP ---\n",
    "        # print(\"  Training Transfer All GP...\")\n",
    "        X_S_rescaled_for_All = scaler_T_train.transform(scaler_S.inverse_transform(X_S))\n",
    "        X_all_train = np.vstack((X_S_rescaled_for_All, X_T_train))\n",
    "        y_all_train = np.concatenate((y_S_scaled_flat, y_T_train_scaled_flat))\n",
    "\n",
    "        gp_transfer_all = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, \n",
    "                                    initial_noise_std=default_noise_gp)\n",
    "        gp_transfer_all.fit(X_all_train, y_all_train, disp=verbose_optimization, maxiter=max_iter_gp,\n",
    "                             model_name_for_print=f\"TransAll Df={Df_strength:.1f}\")\n",
    "        mean_transfer_all, _ = gp_transfer_all.predict(X_T_test)\n",
    "        mae_transfer_all_list.append(mae(y_T_test_scaled_flat, mean_transfer_all))\n",
    "        if verbose_optimization:\n",
    "            print(f\"    Transfer All GP MAE: {mae_transfer_all_list[-1]:.3f}\")\n",
    "            print(f\"    TransAll Optimized Params: {gp_transfer_all.optimized_params_}\")\n",
    "\n",
    "    # --- Plotting ---\n",
    "    plt.style.use('seaborn-v0_8-whitegrid') \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4.5)) # Adjusted figsize for typical paper look\n",
    "\n",
    "    # Left plot: MAE vs D_f\n",
    "    axs[0].plot(Df_values, mae_transfer_all_list, 'g-o', markerfacecolor='none', markeredgecolor='g', markersize=6, linewidth=1.5, label='Transfer All (GP)')\n",
    "    axs[0].plot(Df_values, mae_no_transfer_list, 'b-x', markersize=6, linewidth=1.5, label='No Transfer (GP)') \n",
    "    axs[0].plot(Df_values, mae_atgp_list, 'r-', linewidth=2, label='AT-GP')\n",
    "    \n",
    "    axs[0].set_xlabel('$D_f$', fontsize=12)\n",
    "    axs[0].set_ylabel('MAE', fontsize=12)\n",
    "    axs[0].legend(fontsize=10)\n",
    "    axs[0].set_ylim(0, max(120, 1.1*np.max(mae_transfer_all_list if mae_transfer_all_list else [0]))) # Ensure y-axis accommodates data\n",
    "    axs[0].tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "\n",
    "    # Right plot: Lambda vs D_f\n",
    "    axs[1].plot(Df_values, lambda_atgp_list, 'b-', linewidth=2)\n",
    "    axs[1].set_xlabel('$D_f$', fontsize=12)\n",
    "    axs[1].set_ylabel('$\\\\lambda$', fontsize=14, rotation=0, labelpad=15)\n",
    "    axs[1].set_ylim(min(-0.1, 0.9*np.min(lambda_atgp_list if lambda_atgp_list else [0])), \n",
    "                    max(1.05, 1.1*np.max(lambda_atgp_list if lambda_atgp_list else [0]))) # Dynamic Y lim for lambda\n",
    "    axs[1].tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "\n",
    "    caption_text = (\n",
    "        \"Figure 2: The left figure shows the change to MAE with increasing distance with $f$. \"\n",
    "        \"The results are compared with transfer all and no transfer; The right figure shows \"\n",
    "        \"the change to $\\\\lambda$ with increasing distance with $f$. We can see that $\\\\lambda$ \"\n",
    "        \"is strongly correlated with $D_f$.\"\n",
    "    )\n",
    "    #plt.figtext(0.5, 0.01, caption_text, wrap=True, horizontalalignment='center', fontsize=9)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.1, right=0.95, bottom=0.22, top=0.93, wspace=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    return Df_values, mae_atgp_list, mae_no_transfer_list, mae_transfer_all_list, lambda_atgp_list\n",
    "\n",
    "\n",
    "# %%\n",
    "if __name__ == '__main__':\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    # np.seterr(all='warn') # Use 'warn' or 'raise' to catch numerical issues during debugging\n",
    "    np.seterr(divide='ignore', invalid='ignore', over='ignore') # Typical production setting\n",
    "\n",
    "    # --- Run Figure 2 Reproduction Experiment ---\n",
    "    # Set verbose_optimization_fig2 to True to see optimization details for this experiment.\n",
    "    # It can be slow with verbose output for many D_f points.\n",
    "    verbose_opt_fig2 = False \n",
    "    random_seed_fig2 = 42 # Use a fixed seed for reproducibility\n",
    "    \n",
    "    print(f\"\\nStarting Figure 2 reproduction with seed={random_seed_fig2} and verbose_optimization={verbose_opt_fig2}\")\n",
    "    results_fig2 = run_figure2_experiment(seed=random_seed_fig2, verbose_optimization=verbose_opt_fig2)\n",
    "    print(\"\\nFigure 2 reproduction experiment finished.\")\n",
    "\n",
    "\n",
    "    # --- Optionally run other experiments ---\n",
    "    run_other_experiments = False # Set to True to run these\n",
    "    if run_other_experiments:\n",
    "        verbose_opt_others = False\n",
    "        random_seed_others = 111\n",
    "\n",
    "        print(f\"\\nStarting other experiments with seed={random_seed_others} and verbose_optimization={verbose_opt_others}\")\n",
    "        \n",
    "        # Placeholder for sim_wifi_results = run_simulated_wifi_experiment(...)\n",
    "        # Placeholder for sarcos_results = run_sarcos_experiment(...)\n",
    "        sim_wine_results = run_sarcos_experiment(verbose_optimization=verbose_opt_others, seed=random_seed_others)\n",
    "\n",
    "        print(\"\\n\\n--- OVERALL RESULTS SUMMARY (Other Experiments) ---\")\n",
    "        # if sim_wifi_results:\n",
    "        #     print(\"\\nSimulated WiFi Dataset (Error Distance):\")\n",
    "        #     for model, score in sim_wifi_results.items(): print(f\"  {model}: {score:.4f}\")\n",
    "        # if sarcos_results:\n",
    "        #     print(\"\\nSARCOS Dataset (NMSE):\")\n",
    "        #     for model, score in sarcos_results.items(): print(f\"  {model}: {score:.4f}\")\n",
    "        if sim_wine_results:\n",
    "            print(\"\\nWine Dataset (NMSE):\")\n",
    "            for model, score in sim_wine_results.items(): print(f\"  {model}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Figure 4 reproduction with seed=42, Df=5.0, verbose_optimization=False\n",
      "\n",
      "--- Starting Figure 4 Reproduction Experiment (Df=5.0) ---\n",
      "  Determining lambda_star using all target training data...\n",
      "  Determined lambda_star = -0.6800 (using 100 target samples)\n",
      "  Processing with n_t_current = 1/100\n",
      "  Processing with n_t_current = 10/100\n",
      "  Processing with n_t_current = 20/100\n",
      "  Processing with n_t_current = 30/100\n",
      "  Processing with n_t_current = 40/100\n",
      "  Processing with n_t_current = 50/100\n",
      "  Processing with n_t_current = 60/100\n",
      "  Processing with n_t_current = 70/100\n",
      "  Processing with n_t_current = 80/100\n",
      "  Processing with n_t_current = 90/100\n",
      "  Processing with n_t_current = 100/100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Figure 4 reproduction experiment finished.\n",
      "\n",
      "--- Starting SIMULATED WiFi Localization Experiment ---\n",
      "Source (Sim WiFi): X_S (500, 10), y_S (500,)\n",
      "Target (Sim WiFi) All: X_T_scaled_all (500, 10), y_T (500,)\n",
      "Target Train: X_T_train (25, 10), y_T_train (25,) (approx 5.0%)\n",
      "Target Test: X_T_test (475, 10), y_T_test (475,)\n",
      "\n",
      "--- Training AT-GP Model (Sim WiFi) ---\n",
      "AT-GP Error Distance (Sim WiFi): 6.1403\n",
      "\n",
      "--- Training No Transfer GP Model (Sim WiFi) ---\n",
      "No Transfer GP Error Distance (Sim WiFi): 0.4736\n",
      "\n",
      "--- Training Transfer All GP Model (Sim WiFi) ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 886\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFigure 4 reproduction experiment finished.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Run other experiments\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m sim_wifi_results = \u001b[43mrun_simulated_wifi_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose_optimization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_opt_experiments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed_experiments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    887\u001b[39m sarcos_results = run_sarcos_experiment(verbose_optimization=verbose_opt_experiments, seed=random_seed_experiments)\n\u001b[32m    888\u001b[39m sim_wine_results = run_wine_experiment(verbose_optimization=verbose_opt_experiments, seed=random_seed_experiments)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 853\u001b[39m, in \u001b[36mrun_simulated_wifi_experiment\u001b[39m\u001b[34m(verbose_optimization, seed)\u001b[39m\n\u001b[32m    850\u001b[39m y_all_train = np.concatenate((y_S_raw.ravel(), y_T_train))\n\u001b[32m    852\u001b[39m gp_transfer_all = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n\u001b[32m--> \u001b[39m\u001b[32m853\u001b[39m \u001b[43mgp_transfer_all\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_all_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_all_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose_optimization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name_for_print\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTransfer All GP (Sim WiFi)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gp_transfer_all.fitted:\n\u001b[32m    855\u001b[39m     mean_transfer_all, _ = gp_transfer_all.predict(X_T_test)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 359\u001b[39m, in \u001b[36mSimpleGPR.fit\u001b[39m\u001b[34m(self, X_train, y_train, method, disp, maxiter, model_name_for_print)\u001b[39m\n\u001b[32m    356\u001b[39m bounds = [(\u001b[32m1e-5\u001b[39m, \u001b[32m1e3\u001b[39m), (\u001b[32m1e-5\u001b[39m, \u001b[32m1e3\u001b[39m), (\u001b[32m1e-5\u001b[39m, \u001b[32m1e2\u001b[39m)] \n\u001b[32m    358\u001b[39m objective = \u001b[38;5;28;01mlambda\u001b[39;00m params_opt: -\u001b[38;5;28mself\u001b[39m.log_marginal_likelihood(params_opt, \u001b[38;5;28mself\u001b[39m.X_train, \u001b[38;5;28mself\u001b[39m.y_train)\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m result = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m                  \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdisp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mftol\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disp:\n\u001b[32m    363\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name_for_print\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m optimization finished.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:738\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    735\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    736\u001b[39m                              **options)\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    739\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    741\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    742\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:441\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[39m\n\u001b[32m    433\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    434\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    437\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    438\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    439\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    440\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    443\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    444\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:345\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    343\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m    344\u001b[39m \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:307\u001b[39m, in \u001b[36mScalarFunction._update_grad\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._orig_grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28mself\u001b[39m.g = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[38;5;28mself\u001b[39m.g_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:48\u001b[39m, in \u001b[36m_wrapper_grad.<locals>.wrapped1\u001b[39m\u001b[34m(x, f0)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped1\u001b[39m(x, f0=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     47\u001b[39m     ncalls[\u001b[32m0\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfinite_diff_options\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:523\u001b[39m, in \u001b[36mapprox_derivative\u001b[39m\u001b[34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[39m\n\u001b[32m    520\u001b[39m     use_one_sided = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    526\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:596\u001b[39m, in \u001b[36m_dense_difference\u001b[39m\u001b[34m(fun, x0, f0, h, use_one_sided, method)\u001b[39m\n\u001b[32m    594\u001b[39m     x1[i] += h[i]\n\u001b[32m    595\u001b[39m     dx = x1[i] - x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m     df = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m - f0\n\u001b[32m    597\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33m3-point\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[32m    598\u001b[39m     x1[i] += h[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:474\u001b[39m, in \u001b[36mapprox_derivative.<locals>.fun_wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xp.isdtype(x.dtype, \u001b[33m\"\u001b[39m\u001b[33mreal floating\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    472\u001b[39m     x = xp.astype(x, x0.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m f = np.atleast_1d(\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`fun` return value has \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mmore than 1 dimension.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:21\u001b[39m, in \u001b[36m_wrapper_fun.<locals>.wrapped\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     17\u001b[39m ncalls[\u001b[32m0\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m fx = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isscalar(fx):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 358\u001b[39m, in \u001b[36mSimpleGPR.fit.<locals>.<lambda>\u001b[39m\u001b[34m(params_opt)\u001b[39m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m    Initial params (ls, sf, noise_std): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.round(initial_params,\u001b[32m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    356\u001b[39m bounds = [(\u001b[32m1e-5\u001b[39m, \u001b[32m1e3\u001b[39m), (\u001b[32m1e-5\u001b[39m, \u001b[32m1e3\u001b[39m), (\u001b[32m1e-5\u001b[39m, \u001b[32m1e2\u001b[39m)] \n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m objective = \u001b[38;5;28;01mlambda\u001b[39;00m params_opt: -\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m result = minimize(objective, initial_params, method=method, bounds=bounds, \n\u001b[32m    360\u001b[39m                   options={\u001b[33m'\u001b[39m\u001b[33mdisp\u001b[39m\u001b[33m'\u001b[39m: disp, \u001b[33m'\u001b[39m\u001b[33mmaxiter\u001b[39m\u001b[33m'\u001b[39m: maxiter, \u001b[33m'\u001b[39m\u001b[33mftol\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1e-7\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mgtol\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1e-5\u001b[39m})\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disp:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 325\u001b[39m, in \u001b[36mSimpleGPR.log_marginal_likelihood\u001b[39m\u001b[34m(self, params_array_opt, X, y)\u001b[39m\n\u001b[32m    323\u001b[39m N = X.shape[\u001b[32m0\u001b[39m]\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m N == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m -np.inf \n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m K = \u001b[43mcalculate_covariance_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_kernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m K_noisy = K + current_noise_var * np.eye(N) + jitter * np.eye(N)\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mcalculate_covariance_matrix\u001b[39m\u001b[34m(X1, X2, kernel_func)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcalculate_covariance_matrix\u001b[39m(X1, X2, kernel_func):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkernel_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mSquaredExponentialKernel.__call__\u001b[39m\u001b[34m(self, X1, X2)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X1.shape[\u001b[32m1\u001b[39m] != X2.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX1 and X2 must have the same number of features. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX1.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX2.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m sqdist = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX1\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m) + np.sum(X2**\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m) - \u001b[32m2\u001b[39m * np.dot(X1, X2.T)\n\u001b[32m     32\u001b[39m sqdist = np.clip(sqdist, \u001b[32m0\u001b[39m, np.inf) \u001b[38;5;66;03m# Ensure non-negative\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sigma_f**\u001b[32m2\u001b[39m * np.exp(-\u001b[32m0.5\u001b[39m / \u001b[38;5;28mself\u001b[39m.length_scale**\u001b[32m2\u001b[39m * sqdist)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2466\u001b[39m, in \u001b[36msum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2463\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   2464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m-> \u001b[39m\u001b[32m2466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\harsh\\miniconda3\\envs\\ATGP_env\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg\n",
    "from scipy.optimize import minimize\n",
    "from scipy.io import loadmat # Not strictly needed for this problem, but in original code\n",
    "import pandas as pd # Not strictly needed for this problem, but in original code\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- Kernel Function ---\n",
    "class SquaredExponentialKernel:\n",
    "    def __init__(self, length_scale=1.0, sigma_f=1.0):\n",
    "        self.length_scale = length_scale\n",
    "        self.sigma_f = sigma_f\n",
    "\n",
    "    def get_params(self):\n",
    "        return np.array([self.length_scale, self.sigma_f])\n",
    "\n",
    "    def set_params(self, params):\n",
    "        self.length_scale = params[0]\n",
    "        self.sigma_f = params[1]\n",
    "\n",
    "    def __call__(self, X1, X2):\n",
    "        if X1.ndim == 1: X1 = X1[:, np.newaxis]\n",
    "        if X2.ndim == 1: X2 = X2[:, np.newaxis]\n",
    "\n",
    "        if X1.shape[1] != X2.shape[1]:\n",
    "            raise ValueError(f\"X1 and X2 must have the same number of features. Got {X1.shape[1]} and {X2.shape[1]}\")\n",
    "\n",
    "        sqdist = np.sum(X1**2, 1).reshape(-1, 1) + np.sum(X2**2, 1) - 2 * np.dot(X1, X2.T)\n",
    "        sqdist = np.clip(sqdist, 0, np.inf) # Ensure non-negative\n",
    "\n",
    "        return self.sigma_f**2 * np.exp(-0.5 / self.length_scale**2 * sqdist)\n",
    "\n",
    "# Helper to compute covariance matrix\n",
    "def calculate_covariance_matrix(X1, X2, kernel_func):\n",
    "    return kernel_func(X1, X2)\n",
    "\n",
    "# --- Metrics ---\n",
    "def nmse(y_true, y_pred):\n",
    "    y_true_v = np.asarray(y_true).flatten()\n",
    "    y_pred_v = np.asarray(y_pred).flatten()\n",
    "    if len(y_true_v) == 0 or len(y_pred_v) == 0: return np.nan\n",
    "    mse = np.mean((y_true_v - y_pred_v)**2)\n",
    "    var_true = np.var(y_true_v)\n",
    "    if var_true < 1e-9: # Avoid division by zero if true values are constant\n",
    "        return mse if mse > 1e-9 else 0.0\n",
    "    return mse / var_true\n",
    "\n",
    "def error_distance(y_true, y_pred): # This is MAE for 1D output, or mean Euclidean for multi-output\n",
    "    y_true_v = np.asarray(y_true)\n",
    "    y_pred_v = np.asarray(y_pred)\n",
    "    if y_true_v.ndim == 1: y_true_v = y_true_v.reshape(-1,1)\n",
    "    if y_pred_v.ndim == 1: y_pred_v = y_pred_v.reshape(-1,1)\n",
    "\n",
    "    if y_true_v.shape[0] == 0 or y_pred_v.shape[0] == 0: return np.nan\n",
    "    # For 1D output, this is equivalent to MAE np.mean(np.abs(y_true_v.ravel() - y_pred_v.ravel()))\n",
    "    return np.mean(np.sqrt(np.sum((y_true_v - y_pred_v)**2, axis=1)))\n",
    "\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_true_v = np.asarray(y_true).flatten()\n",
    "    y_pred_v = np.asarray(y_pred).flatten()\n",
    "    if len(y_true_v) == 0 or len(y_pred_v) == 0: return np.nan\n",
    "    return np.mean(np.abs(y_true_v - y_pred_v))\n",
    "\n",
    "# --- AT-GP Model (from paper) ---\n",
    "class ATGP:\n",
    "    def __init__(self, X_S, y_S, X_T, y_T,\n",
    "                 initial_length_scale=1.0, initial_sigma_f=1.0,\n",
    "                 initial_b=1.0, initial_mu=1.0,\n",
    "                 initial_noise_S_std=0.1, initial_noise_T_std=0.1):\n",
    "        self.X_S = X_S\n",
    "        self.y_S = y_S.reshape(-1, 1)\n",
    "        self.X_T = X_T\n",
    "        self.y_T = y_T.reshape(-1, 1)\n",
    "\n",
    "        self._length_scale = initial_length_scale\n",
    "        self._sigma_f = initial_sigma_f\n",
    "        self._b = initial_b\n",
    "        self._mu = initial_mu\n",
    "        self._noise_S_std = initial_noise_S_std\n",
    "        self._noise_T_std = initial_noise_T_std\n",
    "\n",
    "        self.base_kernel = SquaredExponentialKernel(self._length_scale, self._sigma_f)\n",
    "        self.fitted = False\n",
    "        self.optimized_params_ = {}\n",
    "\n",
    "    def _get_params_array(self):\n",
    "        return np.array([self._length_scale, self._sigma_f, self._b, self._mu,\n",
    "                         self._noise_S_std, self._noise_T_std])\n",
    "\n",
    "    def _set_params_from_array(self, params_array):\n",
    "        self._length_scale = params_array[0]\n",
    "        self._sigma_f = params_array[1]\n",
    "        self.base_kernel.set_params(params_array[:2])\n",
    "        self._b = params_array[2]\n",
    "        self._mu = params_array[3]\n",
    "        self._noise_S_std = params_array[4]\n",
    "        self._noise_T_std = params_array[5]\n",
    "\n",
    "    def _get_lambda(self, b_param=None, mu_param=None):\n",
    "        b_to_use = b_param if b_param is not None else self._b\n",
    "        mu_to_use = mu_param if mu_param is not None else self._mu\n",
    "        \n",
    "        b_to_use = max(1e-5, b_to_use) \n",
    "        mu_to_use = max(1e-5, mu_to_use) \n",
    "\n",
    "        term_base = 1.0 / (1.0 + mu_to_use) \n",
    "        lambda_val = -1.0\n",
    "        \n",
    "        try:\n",
    "            pow_term = np.power(term_base, b_to_use)\n",
    "            lambda_val = 2 * pow_term - 1\n",
    "        except (OverflowError, ValueError): \n",
    "             lambda_val = np.sign(2 * (0.5 if term_base > 1 else 0) -1) * 1.0 \n",
    "\n",
    "        return np.clip(lambda_val, -1.0, 1.0)\n",
    "\n",
    "\n",
    "    def log_marginal_likelihood_conditional(self, params_array_opt):\n",
    "        params_array_opt = np.maximum(params_array_opt, 1e-5) \n",
    "\n",
    "        if self.y_T.shape[0] == 0: \n",
    "            return -np.inf\n",
    "\n",
    "        current_length_scale = params_array_opt[0]\n",
    "        current_sigma_f = params_array_opt[1]\n",
    "        temp_kernel = SquaredExponentialKernel(current_length_scale, current_sigma_f)\n",
    "\n",
    "        current_b = params_array_opt[2]\n",
    "        current_mu = params_array_opt[3] \n",
    "        temp_lambda = self._get_lambda(b_param=current_b, mu_param=current_mu)\n",
    "\n",
    "        current_noise_S_var = params_array_opt[4]**2\n",
    "        current_noise_T_var = params_array_opt[5]**2\n",
    "\n",
    "        jitter = 1e-7 \n",
    "\n",
    "        K11 = calculate_covariance_matrix(self.X_S, self.X_S, temp_kernel)\n",
    "        K22 = calculate_covariance_matrix(self.X_T, self.X_T, temp_kernel)\n",
    "        K_TS_base = calculate_covariance_matrix(self.X_T, self.X_S, temp_kernel) \n",
    "\n",
    "        K21 = temp_lambda * K_TS_base \n",
    "        K12 = K21.T \n",
    "\n",
    "        try:\n",
    "            K11_noisy = K11 + current_noise_S_var * np.eye(K11.shape[0]) + jitter * np.eye(K11.shape[0])\n",
    "            L_K11_noisy = np.linalg.cholesky(K11_noisy)\n",
    "            \n",
    "            K11_noisy_inv_yS = scipy.linalg.solve_triangular(L_K11_noisy.T, \n",
    "                                   scipy.linalg.solve_triangular(L_K11_noisy, self.y_S, lower=True, check_finite=False), \n",
    "                                   lower=False, check_finite=False)\n",
    "            mu_t = K21 @ K11_noisy_inv_yS\n",
    "\n",
    "            K11_noisy_inv_K12 = scipy.linalg.solve_triangular(L_K11_noisy.T, \n",
    "                                    scipy.linalg.solve_triangular(L_K11_noisy, K12, lower=True, check_finite=False), \n",
    "                                    lower=False, check_finite=False)\n",
    "\n",
    "            C_t_main_term = K22 - K21 @ K11_noisy_inv_K12\n",
    "            C_t = C_t_main_term + current_noise_T_var * np.eye(K22.shape[0]) + jitter * np.eye(K22.shape[0])\n",
    "\n",
    "            L_Ct = np.linalg.cholesky(C_t)\n",
    "            log_det_Ct = 2 * np.sum(np.log(np.diag(L_Ct)))\n",
    "\n",
    "            y_T_minus_mu_t = self.y_T - mu_t\n",
    "            Ct_inv_y_minus_mu = scipy.linalg.solve_triangular(L_Ct.T, \n",
    "                                    scipy.linalg.solve_triangular(L_Ct, y_T_minus_mu_t, lower=True, check_finite=False),\n",
    "                                    lower=False, check_finite=False)\n",
    "            \n",
    "            term2_quadratic = y_T_minus_mu_t.T @ Ct_inv_y_minus_mu\n",
    "        except np.linalg.LinAlgError:\n",
    "            return -np.inf \n",
    "        \n",
    "        log_likelihood = -0.5 * log_det_Ct - 0.5 * term2_quadratic - len(self.y_T)/2.0 * np.log(2 * np.pi)\n",
    "\n",
    "        if np.isnan(log_likelihood) or not np.isfinite(log_likelihood):\n",
    "            return -np.inf\n",
    "        return log_likelihood.item()\n",
    "\n",
    "    def fit(self, method='L-BFGS-B', disp=False, maxiter=200):\n",
    "        if self.X_T.shape[0] == 0:\n",
    "            if disp: print(\"  AT-GP: Cannot fit with zero target data points. Using initial parameters.\")\n",
    "            self.fitted = True \n",
    "            self.optimized_params_ = dict(zip(['ls', 'sf', 'b', 'mu', 'noise_S_std', 'noise_T_std', 'lambda_val'],\n",
    "                                       list(np.round(self._get_params_array(),4)) + [np.round(self._get_lambda(),4)]))\n",
    "            return None\n",
    "\n",
    "        initial_params = self._get_params_array()\n",
    "        if disp:\n",
    "            print(\"  Starting AT-GP optimization...\")\n",
    "            print(f\"    Initial AT-GP params (ls, sf, b, mu, noise_S_std, noise_T_std): {np.round(initial_params,3)}\")\n",
    "            print(f\"    Initial AT-GP lambda: {self._get_lambda():.3f}\")\n",
    "\n",
    "        bounds = [\n",
    "            (1e-5, 1e3), (1e-5, 1e3), (1e-5, 1e2), (1e-5, 1e2),\n",
    "            (1e-5, 1e2), (1e-5, 1e2)  \n",
    "        ]\n",
    "\n",
    "        objective = lambda params_opt: -self.log_marginal_likelihood_conditional(params_opt)\n",
    "\n",
    "        result = minimize(objective, initial_params, method=method, bounds=bounds, \n",
    "                          options={'disp': disp, 'maxiter': maxiter, 'ftol': 1e-7, 'gtol': 1e-5})\n",
    "\n",
    "        if disp:\n",
    "            print(\"  AT-GP optimization finished.\")\n",
    "            if result:\n",
    "                print(f\"    Success: {result.success}, Message: {result.message}\")\n",
    "                print(f\"    Optimized AT-GP params (ls, sf, b, mu, noise_S_std, noise_T_std): {np.round(result.x,3)}\")\n",
    "\n",
    "        self._set_params_from_array(result.x if result else initial_params)\n",
    "        self.fitted = True\n",
    "        self.optimized_params_ = dict(zip(['ls', 'sf', 'b', 'mu', 'noise_S_std', 'noise_T_std', 'lambda_val'],\n",
    "                                       list(np.round(result.x if result else initial_params,4)) + [np.round(self._get_lambda(),4)]))\n",
    "        if disp:\n",
    "             print(f\"    Optimized AT-GP lambda: {self._get_lambda():.3f}\")\n",
    "        \n",
    "        if result and not result.success and \"CONVERGENCE\" not in result.message.upper():\n",
    "             if disp:\n",
    "                print(f\"    Warning: AT-GP Optimization may not have fully converged: {result.message}\")\n",
    "           \n",
    "        return result\n",
    "\n",
    "    def predict(self, X_star_T): \n",
    "        if not self.fitted :\n",
    "             pass # Allow prediction with initial params if not fitted\n",
    "\n",
    "        lambda_val = self._get_lambda()\n",
    "        noise_S_var_val = self._noise_S_std**2\n",
    "        noise_T_var_val = self._noise_T_std**2 \n",
    "        jitter = 1e-7\n",
    "\n",
    "        N_S = self.X_S.shape[0]\n",
    "        N_T = self.X_T.shape[0]\n",
    "        N_all = N_S + N_T\n",
    "        \n",
    "        y_all = np.vstack((self.y_S, self.y_T)) if N_T > 0 else self.y_S \n",
    "\n",
    "        K_SS = calculate_covariance_matrix(self.X_S, self.X_S, self.base_kernel)\n",
    "        \n",
    "        if N_T > 0:\n",
    "            K_TT = calculate_covariance_matrix(self.X_T, self.X_T, self.base_kernel)\n",
    "            K_ST_base = calculate_covariance_matrix(self.X_S, self.X_T, self.base_kernel) \n",
    "\n",
    "            K_tilde = np.zeros((N_all, N_all))\n",
    "            K_tilde[:N_S, :N_S] = K_SS\n",
    "            K_tilde[N_S:, N_S:] = K_TT\n",
    "            K_tilde[:N_S, N_S:] = lambda_val * K_ST_base\n",
    "            K_tilde[N_S:, :N_S] = lambda_val * K_ST_base.T\n",
    "            \n",
    "            Big_Lambda_diag = np.concatenate([np.full(N_S, noise_S_var_val),\n",
    "                                              np.full(N_T, noise_T_var_val)])\n",
    "        else: # N_T == 0\n",
    "            K_tilde = K_SS\n",
    "            Big_Lambda_diag = np.full(N_S, noise_S_var_val)\n",
    "\n",
    "        Big_Lambda = np.diag(Big_Lambda_diag)\n",
    "        C_tilde = K_tilde + Big_Lambda + jitter * np.eye(K_tilde.shape[0]) # Use K_tilde.shape[0] for N_all or N_S\n",
    "        L_Ctilde = None\n",
    "        try:\n",
    "            L_Ctilde = np.linalg.cholesky(C_tilde)\n",
    "            alpha = scipy.linalg.solve_triangular(L_Ctilde.T, \n",
    "                        scipy.linalg.solve_triangular(L_Ctilde, y_all, lower=True, check_finite=False), \n",
    "                        lower=False, check_finite=False)\n",
    "        except np.linalg.LinAlgError:\n",
    "            C_tilde_inv = np.linalg.pinv(C_tilde)\n",
    "            alpha = C_tilde_inv @ y_all\n",
    "\n",
    "        k_star_S_base = calculate_covariance_matrix(X_star_T, self.X_S, self.base_kernel) \n",
    "        \n",
    "        if N_T > 0:\n",
    "            k_star_T_base = calculate_covariance_matrix(X_star_T, self.X_T, self.base_kernel) \n",
    "            k_x_star_rows = np.hstack((lambda_val * k_star_S_base, k_star_T_base)) \n",
    "        else: # N_T == 0\n",
    "            k_x_star_rows = lambda_val * k_star_S_base\n",
    "\n",
    "        mean_star = k_x_star_rows @ alpha \n",
    "\n",
    "        k_star_star_diag = np.diag(self.base_kernel(X_star_T, X_star_T))\n",
    "        c_diag = k_star_star_diag + noise_T_var_val \n",
    "\n",
    "        if L_Ctilde is not None:\n",
    "            v = scipy.linalg.solve_triangular(L_Ctilde, k_x_star_rows.T, lower=True, check_finite=False)\n",
    "            var_reduction_diag = np.sum(v**2, axis=0) \n",
    "        else: \n",
    "            var_reduction_diag = np.diag(k_x_star_rows @ C_tilde_inv @ k_x_star_rows.T)\n",
    "\n",
    "        variance_star_diag = c_diag - var_reduction_diag\n",
    "        variance_star_diag = np.clip(variance_star_diag, jitter, np.inf) \n",
    "\n",
    "        return mean_star, variance_star_diag.reshape(-1,1)\n",
    "\n",
    "\n",
    "# --- Simple GPR for Baselines ---\n",
    "class SimpleGPR:\n",
    "    def __init__(self, initial_length_scale=1.0, initial_sigma_f=1.0, initial_noise_std=0.1):\n",
    "        self._length_scale = initial_length_scale\n",
    "        self._sigma_f = initial_sigma_f\n",
    "        self._noise_std = initial_noise_std\n",
    "        self.kernel = SquaredExponentialKernel(self._length_scale, self._sigma_f)\n",
    "        self.X_train, self.y_train, self.alpha_, self.L_ = None, None, None, None\n",
    "        self.fitted = False\n",
    "        self.optimized_params_ = {}\n",
    "\n",
    "\n",
    "    def _get_params_array(self):\n",
    "        return np.array([self._length_scale, self._sigma_f, self._noise_std])\n",
    "\n",
    "    def _set_params_from_array(self, params_array):\n",
    "        self._length_scale = params_array[0]\n",
    "        self._sigma_f = params_array[1]\n",
    "        self.kernel.set_params(params_array[:2])\n",
    "        self._noise_std = params_array[2]\n",
    "\n",
    "    def log_marginal_likelihood(self, params_array_opt, X, y):\n",
    "        params_array_opt = np.maximum(params_array_opt, 1e-5) \n",
    "        current_length_scale, current_sigma_f = params_array_opt[0], params_array_opt[1]\n",
    "        temp_kernel = SquaredExponentialKernel(current_length_scale, current_sigma_f)\n",
    "        current_noise_var = params_array_opt[2]**2\n",
    "        jitter = 1e-7\n",
    "\n",
    "        N = X.shape[0]\n",
    "        if N == 0: return -np.inf \n",
    "        K = calculate_covariance_matrix(X, X, temp_kernel)\n",
    "        K_noisy = K + current_noise_var * np.eye(N) + jitter * np.eye(N)\n",
    "\n",
    "        try:\n",
    "            L = np.linalg.cholesky(K_noisy)\n",
    "            alpha_solve = scipy.linalg.solve_triangular(L.T, \n",
    "                                scipy.linalg.solve_triangular(L, y, lower=True, check_finite=False), \n",
    "                                lower=False, check_finite=False)\n",
    "            log_det_K_noisy = 2 * np.sum(np.log(np.diag(L)))\n",
    "        except np.linalg.LinAlgError: \n",
    "            return -np.inf\n",
    "\n",
    "        lml = -0.5 * y.T @ alpha_solve - 0.5 * log_det_K_noisy - N/2.0 * np.log(2 * np.pi)\n",
    "        if np.isnan(lml) or not np.isfinite(lml): return -np.inf\n",
    "        return lml.item()\n",
    "\n",
    "    def fit(self, X_train, y_train, method='L-BFGS-B', disp=False, maxiter=100, model_name_for_print=\"SimpleGPR\"):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train.reshape(-1,1)\n",
    "\n",
    "        if self.X_train.shape[0] == 0:\n",
    "            if disp: print(f\"  {model_name_for_print}: Cannot fit with zero training data points.\")\n",
    "            self.fitted = False \n",
    "            return None\n",
    "\n",
    "\n",
    "        initial_params = self._get_params_array()\n",
    "        if disp:\n",
    "            print(f\"  Starting {model_name_for_print} optimization...\")\n",
    "            print(f\"    Initial params (ls, sf, noise_std): {np.round(initial_params,3)}\")\n",
    "\n",
    "        bounds = [(1e-5, 1e3), (1e-5, 1e3), (1e-5, 1e2)] \n",
    "\n",
    "        objective = lambda params_opt: -self.log_marginal_likelihood(params_opt, self.X_train, self.y_train)\n",
    "        result = minimize(objective, initial_params, method=method, bounds=bounds, \n",
    "                          options={'disp': disp, 'maxiter': maxiter, 'ftol': 1e-7, 'gtol': 1e-5})\n",
    "\n",
    "        if disp:\n",
    "            print(f\"  {model_name_for_print} optimization finished.\")\n",
    "            print(f\"    Success: {result.success}, Message: {result.message}\")\n",
    "            print(f\"    Optimized params (ls, sf, noise_std): {np.round(result.x,3)}\")\n",
    "\n",
    "        self._set_params_from_array(result.x)\n",
    "        self.optimized_params_ = dict(zip(['ls', 'sf', 'noise_std'], np.round(result.x,4)))\n",
    "\n",
    "        K_final = self.kernel(self.X_train, self.X_train)\n",
    "        K_noisy_final = K_final + (self._noise_std**2) * np.eye(self.X_train.shape[0]) + 1e-7 * np.eye(self.X_train.shape[0])\n",
    "        try:\n",
    "            self.L_ = np.linalg.cholesky(K_noisy_final)\n",
    "            self.alpha_ = scipy.linalg.solve_triangular(self.L_.T, \n",
    "                            scipy.linalg.solve_triangular(self.L_, self.y_train, lower=True, check_finite=False), \n",
    "                            lower=False, check_finite=False)\n",
    "            self.fitted = True\n",
    "        except np.linalg.LinAlgError:\n",
    "            if disp:\n",
    "                print(f\"    Warning: Cholesky failed in {model_name_for_print} fit post-optimization. Using PINV for prediction.\")\n",
    "            K_noisy_inv = np.linalg.pinv(K_noisy_final)\n",
    "            self.alpha_ = K_noisy_inv @ self.y_train\n",
    "            self.L_ = None \n",
    "            self.fitted = True \n",
    "        return result\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        if not self.fitted: raise RuntimeError(\"SimpleGPR must be fitted before prediction.\")\n",
    "        if X_star.shape[0] == 0: return np.array([]), np.array([])\n",
    "        \n",
    "        if self.X_train.shape[0] == 0: \n",
    "            k_star_star_diag = np.diag(self.kernel(X_star, X_star))\n",
    "            return np.zeros((X_star.shape[0], 1)), (k_star_star_diag + self._noise_std**2).reshape(-1,1)\n",
    "\n",
    "\n",
    "        jitter = 1e-9\n",
    "\n",
    "        K_star = self.kernel(X_star, self.X_train) \n",
    "        mean_star = K_star @ self.alpha_\n",
    "        \n",
    "        K_star_star_diag = np.diag(self.kernel(X_star, X_star)) \n",
    "        \n",
    "        if self.L_ is not None: \n",
    "            v = scipy.linalg.solve_triangular(self.L_, K_star.T, lower=True, check_finite=False)\n",
    "            var_reduction_diag = np.sum(v**2, axis=0)\n",
    "        else: \n",
    "            K_noisy = self.kernel(self.X_train, self.X_train) + \\\n",
    "                      (self._noise_std**2) * np.eye(self.X_train.shape[0]) + \\\n",
    "                      1e-7 * np.eye(self.X_train.shape[0])\n",
    "            K_noisy_inv = np.linalg.pinv(K_noisy)\n",
    "            var_reduction_diag = np.diag(K_star @ K_noisy_inv @ K_star.T)\n",
    "\n",
    "        variance_star_diag = K_star_star_diag + (self._noise_std**2) - var_reduction_diag\n",
    "        variance_star_diag = np.clip(variance_star_diag, jitter, np.inf) \n",
    "\n",
    "        return mean_star, variance_star_diag.reshape(-1,1)\n",
    "\n",
    "\n",
    "# --- FIGURE 4 REPRODUCTION EXPERIMENT ---\n",
    "def run_figure4_experiment(seed=42, verbose_optimization=False, Df_strength_fig4=10.0):\n",
    "    print(f\"\\n--- Starting Figure 4 Reproduction Experiment (Df={Df_strength_fig4}) ---\")\n",
    "    rng = np.random.RandomState(seed)\n",
    "\n",
    "    n_features = 1\n",
    "    n_source_samples = 100\n",
    "    max_target_train_samples = 100 \n",
    "    n_target_test_samples = 50     \n",
    "    \n",
    "    constant_offset_target = 0.5\n",
    "    noise_std_data = 0.1\n",
    "\n",
    "    global_min_y_for_scaling_fig4 = -0.21723362821122155 \n",
    "    global_max_y_for_scaling_fig4 = 1.0 + constant_offset_target \n",
    "    \n",
    "    def scale_y_to_100(y_vals):\n",
    "        return (y_vals - global_min_y_for_scaling_fig4) / \\\n",
    "               (global_max_y_for_scaling_fig4 - global_min_y_for_scaling_fig4) * 100\n",
    "\n",
    "    scaled_noise_estimate_fig4 = noise_std_data * 100 / (global_max_y_for_scaling_fig4 - global_min_y_for_scaling_fig4)\n",
    "\n",
    "    X_S_raw = rng.uniform(-15, -5, size=(n_source_samples, n_features))\n",
    "    y_S_unscaled = np.sinc(X_S_raw) + rng.randn(n_source_samples, n_features) * noise_std_data\n",
    "    y_S_scaled_flat = scale_y_to_100(y_S_unscaled.ravel())\n",
    "\n",
    "    total_target_samples_needed = max_target_train_samples + n_target_test_samples\n",
    "    X_T_overall_pool_raw = rng.uniform(5, 15, size=(total_target_samples_needed, n_features))\n",
    "    y_T_overall_pool_unscaled = np.sinc(X_T_overall_pool_raw - Df_strength_fig4) + constant_offset_target + \\\n",
    "                                rng.randn(total_target_samples_needed, n_features) * noise_std_data\n",
    "    y_T_overall_pool_scaled_flat = scale_y_to_100(y_T_overall_pool_unscaled.ravel())\n",
    "\n",
    "    X_T_train_pool_raw = X_T_overall_pool_raw[:max_target_train_samples]\n",
    "    y_T_train_pool_scaled_flat = y_T_overall_pool_scaled_flat[:max_target_train_samples]\n",
    "    X_T_test_raw = X_T_overall_pool_raw[max_target_train_samples:]\n",
    "    y_T_test_scaled_flat = y_T_overall_pool_scaled_flat[max_target_train_samples:]\n",
    "\n",
    "    scaler_S = StandardScaler()\n",
    "    X_S = scaler_S.fit_transform(X_S_raw)\n",
    "\n",
    "    scaler_T_pool = StandardScaler()\n",
    "    X_T_train_pool_scaled = scaler_T_pool.fit_transform(X_T_train_pool_raw)\n",
    "    X_T_test_scaled = scaler_T_pool.transform(X_T_test_raw) \n",
    "\n",
    "    default_ls = 1.0\n",
    "    default_sf = 10.0 \n",
    "    default_noise_gp = max(1.0, scaled_noise_estimate_fig4)\n",
    "    default_b, default_mu = 1.0, 1.0 \n",
    "    max_iter_fit = 50 \n",
    "\n",
    "    print(\"  Determining lambda_star using all target training data...\")\n",
    "    atgp_model_for_lambda_star = ATGP(X_S, y_S_scaled_flat, \n",
    "                                      X_T_train_pool_scaled, y_T_train_pool_scaled_flat,\n",
    "                                      initial_length_scale=default_ls, initial_sigma_f=default_sf,\n",
    "                                      initial_b=default_b, initial_mu=default_mu,\n",
    "                                      initial_noise_S_std=default_noise_gp, \n",
    "                                      initial_noise_T_std=default_noise_gp)\n",
    "    atgp_model_for_lambda_star.fit(disp=verbose_optimization, maxiter=max_iter_fit)\n",
    "    lambda_star = atgp_model_for_lambda_star._get_lambda()\n",
    "    print(f\"  Determined lambda_star = {lambda_star:.4f} (using {max_target_train_samples} target samples)\")\n",
    "    if verbose_optimization:\n",
    "        print(f\"    Params for lambda_star: {atgp_model_for_lambda_star.optimized_params_}\")\n",
    "\n",
    "\n",
    "    num_data_values = np.arange(1, max_target_train_samples + 1)\n",
    "    lambda_diffs = []\n",
    "    maes_on_test = []\n",
    "\n",
    "    for i, n_t_current in enumerate(num_data_values):\n",
    "        if (i + 1) % 10 == 0 or i == 0 : \n",
    "             print(f\"  Processing with n_t_current = {n_t_current}/{max_target_train_samples}\")\n",
    "        \n",
    "        X_T_train_iter = X_T_train_pool_scaled[:n_t_current]\n",
    "        y_T_train_iter_flat = y_T_train_pool_scaled_flat[:n_t_current]\n",
    "\n",
    "        atgp_iter_model = ATGP(X_S, y_S_scaled_flat, X_T_train_iter, y_T_train_iter_flat,\n",
    "                               initial_length_scale=default_ls, initial_sigma_f=default_sf,\n",
    "                               initial_b=default_b, initial_mu=default_mu,\n",
    "                               initial_noise_S_std=default_noise_gp, \n",
    "                               initial_noise_T_std=default_noise_gp)\n",
    "        \n",
    "        atgp_iter_model.fit(disp=False, maxiter=max_iter_fit) \n",
    "        \n",
    "        current_lambda = atgp_iter_model._get_lambda()\n",
    "        lambda_diffs.append(np.abs(current_lambda - lambda_star))\n",
    "        \n",
    "        mean_pred_test, _ = atgp_iter_model.predict(X_T_test_scaled)\n",
    "        mae_test = mae(y_T_test_scaled_flat, mean_pred_test)\n",
    "        maes_on_test.append(mae_test)\n",
    "\n",
    "        if verbose_optimization and ( (i + 1) % 20 == 0 or i == 0): \n",
    "            print(f\"    n_t={n_t_current}: Lambda={current_lambda:.3f}, |L-L*|={lambda_diffs[-1]:.3f}, MAE={mae_test:.3f}\")\n",
    "\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5)) \n",
    "\n",
    "    axs[0].plot(num_data_values, lambda_diffs, 'b-', linewidth=1.5)\n",
    "    axs[0].set_xlabel('Num. of Data', fontsize=12)\n",
    "    axs[0].set_ylabel('$|\\\\lambda - \\\\lambda^*|$', fontsize=14)\n",
    "    axs[0].set_ylim(0, 0.45) \n",
    "    axs[0].set_xlim(0, max_target_train_samples)\n",
    "    axs[0].tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "\n",
    "    axs[1].plot(num_data_values, maes_on_test, 'b-', linewidth=1.5)\n",
    "    axs[1].set_xlabel('Num. of Data', fontsize=12)\n",
    "    axs[1].set_ylabel('MAE', fontsize=12)\n",
    "    axs[1].set_ylim(0, 50) \n",
    "    axs[1].set_xlim(0, max_target_train_samples)\n",
    "    axs[1].tick_params(axis='both', which='major', labelsize=10)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.1, right=0.95, bottom=0.18, top=0.90, wspace=0.25)\n",
    "    plt.show()\n",
    "\n",
    "    return num_data_values, lambda_diffs, maes_on_test\n",
    "\n",
    "def run_wine_experiment(verbose_optimization, seed):\n",
    "    print(\"\\n--- Starting WINE Dataset Experiment ---\")\n",
    "    try:\n",
    "        wine_white_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')\n",
    "        wine_red_df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load wine datasets: {e}. Skipping WINE experiment.\")\n",
    "        return None\n",
    "\n",
    "    X_S_raw = wine_white_df.drop('quality', axis=1).values\n",
    "    y_S_raw = wine_white_df['quality'].values\n",
    "    X_T_raw = wine_red_df.drop('quality', axis=1).values\n",
    "    y_T_raw = wine_red_df['quality'].values\n",
    "\n",
    "    scaler_S = StandardScaler()\n",
    "    X_S = scaler_S.fit_transform(X_S_raw)\n",
    "\n",
    "    scaler_T_all_wine = StandardScaler()\n",
    "    X_T_scaled_all = scaler_T_all_wine.fit_transform(X_T_raw)\n",
    "\n",
    "    X_T_train, X_T_test, y_T_train, y_T_test = train_test_split(\n",
    "        X_T_scaled_all, y_T_raw, train_size=0.05, random_state=seed\n",
    "    )\n",
    "    \n",
    "    if X_T_train.shape[0] < 2:\n",
    "        print(\"Not enough target training samples for WINE after split. Skipping.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    print(f\"Source (White Wine): X_S {X_S.shape}, y_S {y_S_raw.shape}\")\n",
    "    print(f\"Target (Red Wine) All: X_T_scaled_all {X_T_scaled_all.shape}, y_T {y_T_raw.shape}\")\n",
    "    print(f\"Target Train: X_T_train {X_T_train.shape}, y_T_train {y_T_train.shape} (approx {X_T_train.shape[0]/X_T_raw.shape[0]*100:.1f}%)\")\n",
    "    print(f\"Target Test: X_T_test {X_T_test.shape}, y_T_test {y_T_test.shape}\")\n",
    "\n",
    "    results = {}\n",
    "    default_ls, default_sf, default_noise = 1.0, 1.0, 0.5\n",
    "    default_b, default_mu = 1.0, 1.0 \n",
    "\n",
    "    print(\"\\n--- Training AT-GP Model (Wine) ---\")\n",
    "    atgp_model = ATGP(X_S, y_S_raw, X_T_train, y_T_train,\n",
    "                      initial_length_scale=default_ls, initial_sigma_f=default_sf,\n",
    "                      initial_b=default_b, initial_mu=default_mu,\n",
    "                      initial_noise_S_std=default_noise, initial_noise_T_std=default_noise)\n",
    "    atgp_model.fit(disp=verbose_optimization, maxiter=100)\n",
    "    mean_atgp, _ = atgp_model.predict(X_T_test)\n",
    "    results['AT-GP'] = nmse(y_T_test, mean_atgp)\n",
    "    print(f\"AT-GP NMSE (Wine): {results['AT-GP']:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Training No Transfer GP Model (Wine) ---\")\n",
    "    gp_no_transfer = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_no_transfer.fit(X_T_train, y_T_train, disp=verbose_optimization, maxiter=100, model_name_for_print=\"No Transfer GP (Wine)\")\n",
    "    if gp_no_transfer.fitted:\n",
    "        mean_no_transfer, _ = gp_no_transfer.predict(X_T_test)\n",
    "        results['No Transfer GP'] = nmse(y_T_test, mean_no_transfer)\n",
    "        print(f\"No Transfer GP NMSE (Wine): {results['No Transfer GP']:.4f}\")\n",
    "    else:\n",
    "        results['No Transfer GP'] = np.nan\n",
    "        print(f\"No Transfer GP NMSE (Wine): Failed to fit.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Training Transfer All GP Model (Wine) ---\")\n",
    "    X_S_rescaled_for_All = scaler_T_all_wine.transform(scaler_S.inverse_transform(X_S))\n",
    "    X_all_train = np.vstack((X_S_rescaled_for_All, X_T_train))\n",
    "    y_all_train = np.concatenate((y_S_raw, y_T_train))\n",
    "\n",
    "    gp_transfer_all = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_transfer_all.fit(X_all_train, y_all_train, disp=verbose_optimization, maxiter=100, model_name_for_print=\"Transfer All GP (Wine)\")\n",
    "    if gp_transfer_all.fitted:\n",
    "        mean_transfer_all, _ = gp_transfer_all.predict(X_T_test)\n",
    "        results['Transfer All GP'] = nmse(y_T_test, mean_transfer_all)\n",
    "        print(f\"Transfer All GP NMSE (Wine): {results['Transfer All GP']:.4f}\")\n",
    "    else:\n",
    "        results['Transfer All GP'] = np.nan\n",
    "        print(f\"Transfer All GP NMSE (Wine): Failed to fit.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Summary of NMSE Results on WINE Dataset ---\")\n",
    "    for model_name, score in results.items():\n",
    "        print(f\"{model_name}: {score:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_sarcos_experiment(verbose_optimization, seed):\n",
    "    print(\"\\n--- Starting SARCOS Dataset Experiment ---\")\n",
    "    try:\n",
    "        # Users might need to change these paths or download the files\n",
    "        input_file_path = 'sarcos_inv.mat' \n",
    "        output_file_path = 'sarcos_inv_test.mat'\n",
    "\n",
    "        sarcos_inputs_full = loadmat(input_file_path)['sarcos_inv']  \n",
    "        sarcos_outputs_full = loadmat(output_file_path)['sarcos_inv_test']\n",
    "\n",
    "        print(f\"Loaded sarcos_inputs_full: {sarcos_inputs_full.shape}\")\n",
    "        print(f\"Loaded sarcos_outputs_full: {sarcos_outputs_full.shape}\")\n",
    "\n",
    "        num_common_samples = min(sarcos_inputs_full.shape[0], sarcos_outputs_full.shape[0])\n",
    "\n",
    "        if num_common_samples == 0:\n",
    "            print(\"No common samples found or one of the files is empty. Skipping SARCOS.\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Working with {num_common_samples} common samples.\")\n",
    "\n",
    "        sarcos_inputs_matched = sarcos_inputs_full[:num_common_samples, :]\n",
    "        sarcos_outputs_matched = sarcos_outputs_full[:num_common_samples, :]\n",
    "\n",
    "        if sarcos_outputs_matched.shape[1] < 2:\n",
    "            print(f\"SARCOS output data has only {sarcos_outputs_matched.shape[1]} joint(s). Need at least 2. Skipping.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"SARCOS .mat files ('{input_file_path}', '{output_file_path}') not found. Please download them or check paths. Skipping SARCOS experiment.\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError loading SARCOS data: {e}. Make sure the keys ('sarcos_inv', 'sarcos_inv_test') are correct. Skipping SARCOS experiment.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SARCOS data: {e}. Skipping SARCOS experiment.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    n_source_samples_desired = 1000\n",
    "    n_target_total_samples_desired = 1000\n",
    "\n",
    "    if n_source_samples_desired + n_target_total_samples_desired > num_common_samples:\n",
    "        print(f\"Desired samples ({n_source_samples_desired + n_target_total_samples_desired}) exceed available common samples ({num_common_samples}). Adjusting.\")\n",
    "        scale_factor = num_common_samples / (n_source_samples_desired + n_target_total_samples_desired)\n",
    "        n_source_samples = int(n_source_samples_desired * scale_factor)\n",
    "        n_target_total_samples = num_common_samples - n_source_samples\n",
    "        min_target_for_split = 20\n",
    "        if n_target_total_samples < min_target_for_split and num_common_samples >= n_source_samples + min_target_for_split :\n",
    "            n_target_total_samples = min_target_for_split\n",
    "            n_source_samples = num_common_samples - n_target_total_samples\n",
    "        elif n_target_total_samples < min_target_for_split:\n",
    "            print(f\"Not enough common samples ({num_common_samples}) to satisfy minimum target samples for split. Skipping.\")\n",
    "            return None\n",
    "\n",
    "        if n_source_samples <= 0 :\n",
    "            if num_common_samples > n_target_total_samples:\n",
    "                n_source_samples = num_common_samples - n_target_total_samples\n",
    "            else:\n",
    "                print(\"Cannot allocate source samples. Skipping SARCOS.\")\n",
    "                return None\n",
    "        print(f\"Adjusted: n_source_samples={n_source_samples}, n_target_total_samples={n_target_total_samples}\")\n",
    "    else:\n",
    "        n_source_samples = n_source_samples_desired\n",
    "        n_target_total_samples = n_target_total_samples_desired\n",
    "    \n",
    "    if n_source_samples <= 0 or n_target_total_samples <= 0:\n",
    "        print(\"No samples allocated for source or target after adjustment. Skipping SARCOS.\")\n",
    "        return None\n",
    "\n",
    "    indices = np.random.RandomState(seed).permutation(num_common_samples)\n",
    "    \n",
    "    source_indices_from_perm = indices[:n_source_samples]\n",
    "    target_indices_from_perm = indices[n_source_samples : n_source_samples + n_target_total_samples]\n",
    "\n",
    "    X_S_raw = sarcos_inputs_matched[source_indices_from_perm, :]\n",
    "    y_S_raw = sarcos_outputs_matched[source_indices_from_perm, 0]\n",
    "\n",
    "    X_T_raw_all = sarcos_inputs_matched[target_indices_from_perm, :]\n",
    "    y_T_raw_all = sarcos_outputs_matched[target_indices_from_perm, 1]\n",
    "\n",
    "    scaler_S = StandardScaler()\n",
    "    X_S = scaler_S.fit_transform(X_S_raw)\n",
    "\n",
    "    scaler_T_all_sarcos = StandardScaler()\n",
    "    X_T_scaled_all = scaler_T_all_sarcos.fit_transform(X_T_raw_all)\n",
    "\n",
    "    if y_T_raw_all.shape[0] < 2:\n",
    "        print(f\"Not enough samples in y_T_raw_all ({y_T_raw_all.shape[0]}) to split. Skipping SARCOS.\")\n",
    "        return None\n",
    "\n",
    "    train_size_target_actual = 0.05\n",
    "    num_train_target = int(y_T_raw_all.shape[0] * train_size_target_actual)\n",
    "\n",
    "    if num_train_target < 2:\n",
    "        if y_T_raw_all.shape[0] >= 2:\n",
    "            num_train_target = 2\n",
    "            train_size_target_actual = num_train_target / y_T_raw_all.shape[0]\n",
    "        else: \n",
    "            print(f\"Cannot get 2 training samples from target data of size {y_T_raw_all.shape[0]}. Skipping SARCOS.\")\n",
    "            return None\n",
    "    \n",
    "    if y_T_raw_all.shape[0] - num_train_target < 1:\n",
    "        print(f\"Not enough samples for testing after allocating {num_train_target} for training from {y_T_raw_all.shape[0]}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    X_T_train, X_T_test, y_T_train, y_T_test = train_test_split(\n",
    "        X_T_scaled_all, y_T_raw_all, train_size=train_size_target_actual, random_state=seed\n",
    "    )\n",
    "    \n",
    "    if X_T_train.shape[0] < 2: \n",
    "        print(\"Not enough target training samples for SARCOS after split. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Source (SARCOS Joint 1): X_S {X_S.shape}, y_S {y_S_raw.shape}\")\n",
    "    print(f\"Target Pool (SARCOS Joint 2): X_T_raw_all {X_T_raw_all.shape}, y_T_raw_all {y_T_raw_all.shape}\")\n",
    "    print(f\"Target Train: X_T_train {X_T_train.shape}, y_T_train {y_T_train.shape} (train_size={train_size_target_actual*100:.1f}%)\")\n",
    "    print(f\"Target Test: X_T_test {X_T_test.shape}, y_T_test {y_T_test.shape}\")\n",
    "\n",
    "    results = {}\n",
    "    default_ls, default_sf, default_noise = 1.0, 1.0, 0.1 \n",
    "    default_b, default_mu = 1.0, 1.0\n",
    "    max_iter_sarcos = 30 \n",
    "\n",
    "    print(f\"\\n--- Training AT-GP Model (SARCOS, max_iter={max_iter_sarcos}) ---\")\n",
    "    atgp_model = ATGP(X_S, y_S_raw, X_T_train, y_T_train,\n",
    "                      initial_length_scale=default_ls, initial_sigma_f=default_sf,\n",
    "                      initial_b=default_b, initial_mu=default_mu,\n",
    "                      initial_noise_S_std=default_noise, initial_noise_T_std=default_noise)\n",
    "    atgp_model.fit(disp=verbose_optimization, maxiter=max_iter_sarcos)\n",
    "    mean_atgp, _ = atgp_model.predict(X_T_test)\n",
    "    results['AT-GP'] = nmse(y_T_test, mean_atgp)\n",
    "    print(f\"AT-GP NMSE (SARCOS): {results['AT-GP']:.4f}\")\n",
    "\n",
    "    print(f\"\\n--- Training No Transfer GP Model (SARCOS, max_iter={max_iter_sarcos}) ---\")\n",
    "    gp_no_transfer = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_no_transfer.fit(X_T_train, y_T_train, disp=verbose_optimization, maxiter=max_iter_sarcos, model_name_for_print=\"No Transfer GP (SARCOS)\")\n",
    "    if gp_no_transfer.fitted:\n",
    "        mean_no_transfer, _ = gp_no_transfer.predict(X_T_test)\n",
    "        results['No Transfer GP'] = nmse(y_T_test, mean_no_transfer)\n",
    "        print(f\"No Transfer GP NMSE (SARCOS): {results['No Transfer GP']:.4f}\")\n",
    "    else:\n",
    "        results['No Transfer GP'] = np.nan\n",
    "        print(f\"No Transfer GP NMSE (SARCOS): Failed to fit.\")\n",
    "\n",
    "\n",
    "    print(f\"\\n--- Training Transfer All GP Model (SARCOS, max_iter={max_iter_sarcos}) ---\")\n",
    "    X_S_rescaled_for_All = scaler_T_all_sarcos.transform(scaler_S.inverse_transform(X_S))\n",
    "    X_all_train = np.vstack((X_S_rescaled_for_All, X_T_train))\n",
    "    y_all_train = np.concatenate((y_S_raw, y_T_train))\n",
    "\n",
    "    gp_transfer_all = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_transfer_all.fit(X_all_train, y_all_train, disp=verbose_optimization, maxiter=max_iter_sarcos, model_name_for_print=\"Transfer All GP (SARCOS)\")\n",
    "    if gp_transfer_all.fitted:\n",
    "        mean_transfer_all, _ = gp_transfer_all.predict(X_T_test)\n",
    "        results['Transfer All GP'] = nmse(y_T_test, mean_transfer_all)\n",
    "        print(f\"Transfer All GP NMSE (SARCOS): {results['Transfer All GP']:.4f}\")\n",
    "    else:\n",
    "        results['Transfer All GP'] = np.nan\n",
    "        print(f\"Transfer All GP NMSE (SARCOS): Failed to fit.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Summary of NMSE Results on SARCOS Dataset ---\")\n",
    "    for model_name, score in results.items():\n",
    "        print(f\"{model_name}: {score:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_simulated_wifi_experiment(verbose_optimization, seed):\n",
    "    print(\"\\n--- Starting SIMULATED WiFi Localization Experiment ---\")\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n_features = 10\n",
    "    n_source_samples = 500\n",
    "    n_target_samples_all = 500 \n",
    "    \n",
    "    w_S = rng.randn(n_features, 1)\n",
    "    X_S_raw = rng.rand(n_source_samples, n_features) * 10\n",
    "    y_S_raw = X_S_raw @ w_S + rng.randn(n_source_samples, 1) * 0.5 \n",
    "\n",
    "    delta_w = rng.randn(n_features, 1) * 0.5 \n",
    "    w_T = w_S + delta_w\n",
    "    X_T_raw_all = rng.rand(n_target_samples_all, n_features) * 10 + rng.rand(1, n_features) * 2\n",
    "    y_T_raw_all = X_T_raw_all @ w_T + rng.randn(n_target_samples_all, 1) * 0.5 \n",
    "\n",
    "    scaler_S = StandardScaler()\n",
    "    X_S = scaler_S.fit_transform(X_S_raw)\n",
    "\n",
    "    scaler_T_all_wifi = StandardScaler()\n",
    "    X_T_scaled_all = scaler_T_all_wifi.fit_transform(X_T_raw_all)\n",
    "\n",
    "    X_T_train, X_T_test, y_T_train, y_T_test = train_test_split(\n",
    "        X_T_scaled_all, y_T_raw_all.ravel(), train_size=0.05, random_state=seed\n",
    "    )\n",
    "    if X_T_train.shape[0] < 2 :\n",
    "        print(\"Not enough target training samples for WiFi Sim after split. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Source (Sim WiFi): X_S {X_S.shape}, y_S {y_S_raw.ravel().shape}\")\n",
    "    print(f\"Target (Sim WiFi) All: X_T_scaled_all {X_T_scaled_all.shape}, y_T {y_T_raw_all.ravel().shape}\")\n",
    "    print(f\"Target Train: X_T_train {X_T_train.shape}, y_T_train {y_T_train.shape} (approx {X_T_train.shape[0]/X_T_raw_all.shape[0]*100:.1f}%)\")\n",
    "    print(f\"Target Test: X_T_test {X_T_test.shape}, y_T_test {y_T_test.shape}\")\n",
    "\n",
    "    results = {}\n",
    "    default_ls, default_sf, default_noise = 1.0, 1.0, 0.2\n",
    "    default_b, default_mu = 1.0, 1.0\n",
    "\n",
    "    print(\"\\n--- Training AT-GP Model (Sim WiFi) ---\")\n",
    "    atgp_model = ATGP(X_S, y_S_raw.ravel(), X_T_train, y_T_train,\n",
    "                      initial_length_scale=default_ls, initial_sigma_f=default_sf,\n",
    "                      initial_b=default_b, initial_mu=default_mu,\n",
    "                      initial_noise_S_std=default_noise, initial_noise_T_std=default_noise)\n",
    "    atgp_model.fit(disp=verbose_optimization, maxiter=100)\n",
    "    mean_atgp, _ = atgp_model.predict(X_T_test)\n",
    "    results['AT-GP'] = error_distance(y_T_test, mean_atgp)\n",
    "    print(f\"AT-GP Error Distance (Sim WiFi): {results['AT-GP']:.4f}\")\n",
    "\n",
    "    print(\"\\n--- Training No Transfer GP Model (Sim WiFi) ---\")\n",
    "    gp_no_transfer = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_no_transfer.fit(X_T_train, y_T_train, disp=verbose_optimization, maxiter=100, model_name_for_print=\"No Transfer GP (Sim WiFi)\")\n",
    "    if gp_no_transfer.fitted:\n",
    "        mean_no_transfer, _ = gp_no_transfer.predict(X_T_test)\n",
    "        results['No Transfer GP'] = error_distance(y_T_test, mean_no_transfer)\n",
    "        print(f\"No Transfer GP Error Distance (Sim WiFi): {results['No Transfer GP']:.4f}\")\n",
    "    else:\n",
    "        results['No Transfer GP'] = np.nan\n",
    "        print(f\"No Transfer GP Error Distance (Sim WiFi): Failed to fit.\")\n",
    "\n",
    "    print(\"\\n--- Training Transfer All GP Model (Sim WiFi) ---\")\n",
    "    X_S_rescaled_for_All = scaler_T_all_wifi.transform(scaler_S.inverse_transform(X_S))\n",
    "    X_all_train = np.vstack((X_S_rescaled_for_All, X_T_train))\n",
    "    y_all_train = np.concatenate((y_S_raw.ravel(), y_T_train))\n",
    "\n",
    "    gp_transfer_all = SimpleGPR(initial_length_scale=default_ls, initial_sigma_f=default_sf, initial_noise_std=default_noise)\n",
    "    gp_transfer_all.fit(X_all_train, y_all_train, disp=verbose_optimization, maxiter=100, model_name_for_print=\"Transfer All GP (Sim WiFi)\")\n",
    "    if gp_transfer_all.fitted:\n",
    "        mean_transfer_all, _ = gp_transfer_all.predict(X_T_test)\n",
    "        results['Transfer All GP'] = error_distance(y_T_test, mean_transfer_all)\n",
    "        print(f\"Transfer All GP Error Distance (Sim WiFi): {results['Transfer All GP']:.4f}\")\n",
    "    else:\n",
    "        results['Transfer All GP'] = np.nan\n",
    "        print(f\"Transfer All GP Error Distance (Sim WiFi): Failed to fit.\")\n",
    "\n",
    "    print(\"\\n--- Summary of Error Distance Results on SIMULATED WiFi Dataset ---\")\n",
    "    for model_name, score in results.items():\n",
    "        print(f\"{model_name}: {score:.4f}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.set_printoptions(precision=4, suppress=True)\n",
    "    np.seterr(all='ignore') \n",
    "    \n",
    "    verbose_opt_experiments = False \n",
    "    random_seed_experiments = 111\n",
    "\n",
    "    # Run Figure 4 experiment\n",
    "    verbose_opt_fig4 = False \n",
    "    random_seed_fig4 = 42 \n",
    "    Df_for_fig4 = 5.0 \n",
    "    print(f\"\\nStarting Figure 4 reproduction with seed={random_seed_fig4}, Df={Df_for_fig4}, verbose_optimization={verbose_opt_fig4}\")\n",
    "    results_fig4 = run_figure4_experiment(seed=random_seed_fig4, \n",
    "                                          verbose_optimization=verbose_opt_fig4,\n",
    "                                          Df_strength_fig4=Df_for_fig4)\n",
    "    print(\"\\nFigure 4 reproduction experiment finished.\")\n",
    "\n",
    "    # Run other experiments\n",
    "    sim_wifi_results = run_simulated_wifi_experiment(verbose_optimization=verbose_opt_experiments, seed=random_seed_experiments)\n",
    "    sarcos_results = run_sarcos_experiment(verbose_optimization=verbose_opt_experiments, seed=random_seed_experiments)\n",
    "    sim_wine_results = run_wine_experiment(verbose_optimization=verbose_opt_experiments, seed=random_seed_experiments)\n",
    "\n",
    "    print(\"\\n\\n--- OVERALL RESULTS SUMMARY ---\")\n",
    "    if sim_wifi_results:\n",
    "        print(\"\\nSimulated WiFi Dataset (Error Distance):\")\n",
    "        for model, score_val in sim_wifi_results.items(): print(f\"  {model}: {score_val:.4f}\")\n",
    "    \n",
    "    if sarcos_results:\n",
    "        print(\"\\nSARCOS Dataset (Subsampled, J1->J2, NMSE):\")\n",
    "        for model, score_val in sarcos_results.items(): print(f\"  {model}: {score_val:.4f}\")\n",
    "\n",
    "    if sim_wine_results:\n",
    "        print(\"\\nWine Dataset (NMSE):\") # Changed from \"Simulated Wine\" to \"Wine\"\n",
    "        for model, score_val in sim_wine_results.items(): print(f\"  {model}: {score_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
